{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Data Ingestion => docs\n",
    "- Text Splitter => splitted_docs\n",
    "- Embedding =>\n",
    "- Retrieval Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')\n",
    "os.environ['LANGSMITH_API_KEY'] = os.getenv(\"LANGSMITH_API_KEY\")\n",
    "os.environ['LANGSMITH_TRACING'] = \"true\"\n",
    "os.environ['LANGSMITH_PROJECT'] = \"Components_Of_Langchain\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Ingestion\n",
    "- From the website we need to scrap the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://huggingface.co/docs/transformers/index', 'title': 'ğŸ¤— Transformers', 'description': 'Weâ€™re on a journey to advance and democratize artificial intelligence through open source and open science.', 'language': 'No language found.'}, page_content='\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nğŸ¤— Transformers\\n\\n\\n\\n\\n\\n\\n\\n\\nHugging Face\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\t\\t\\tModels\\n\\n\\t\\t\\t\\t\\tDatasets\\n\\n\\t\\t\\t\\t\\tSpaces\\n\\n\\t\\t\\t\\t\\tPosts\\n\\n\\t\\t\\t\\t\\tDocs\\n\\n\\t\\t\\t\\t\\tEnterprise\\n\\nPricing\\n\\t\\t\\t\\n\\n\\n\\n\\n\\n\\nLog In\\n\\t\\t\\t\\t\\nSign Up\\n\\t\\t\\t\\t\\t\\n\\n\\n\\nTransformers documentation\\n\\t\\t\\t\\nğŸ¤— Transformers\\n\\n\\n\\nTransformers\\n\\nğŸ¡ View all docsAWS Trainium & InferentiaAccelerateAmazon SageMakerArgillaAutoTrainBitsandbytesChat UICompetitionsDataset viewerDatasetsDiffusersDistilabelEvaluateGoogle CloudGoogle TPUsGradioHubHub Python LibraryHugging Face Generative AI Services (HUGS)Huggingface.jsInference API (serverless)Inference Endpoints (dedicated)LeaderboardsLightevalOptimumPEFTSafetensorsSentence TransformersTRLTasksText Embeddings InferenceText Generation InferenceTokenizersTransformersTransformers.jssmolagentstimm\\n\\nSearch documentation\\n\\n\\nmainv4.48.0v4.47.1v4.46.3v4.45.2v4.44.2v4.43.4v4.42.4v4.41.2v4.40.2v4.39.3v4.38.2v4.37.2v4.36.1v4.35.2v4.34.1v4.33.3v4.32.1v4.31.0v4.30.0v4.29.1v4.28.1v4.27.2v4.26.1v4.25.1v4.24.0v4.23.1v4.22.2v4.21.3v4.20.1v4.19.4v4.18.0v4.17.0v4.16.2v4.15.0v4.14.1v4.13.0v4.12.5v4.11.3v4.10.1v4.9.2v4.8.2v4.7.0v4.6.0v4.5.1v4.4.2v4.3.3v4.2.2v4.1.1v4.0.1v3.5.1v3.4.0v3.3.1v3.2.0v3.1.0v3.0.2v2.11.0v2.10.0v2.9.1v2.8.0v2.7.0v2.6.0v2.5.1v2.4.1v2.3.0v2.2.2v2.1.1v2.0.0v1.2.0v1.1.0v1.0.0doc-builder-html\\nARDEENESFRHIITJAKOPTTETRZH\\n\\n\\n\\n\\n\\n\\n\\n\\nGet started\\n\\n\\nğŸ¤— Transformers\\nQuick tour\\nInstallation\\nAdding a new model to `transformers`\\n\\n\\nTutorials\\n\\n\\nRun inference with pipelines\\nWrite portable code with AutoClass\\nPreprocess data\\nFine-tune a pretrained model\\nTrain with a script\\nSet up distributed training with ğŸ¤— Accelerate\\nLoad and train adapters with ğŸ¤— PEFT\\nShare your model\\nAgents 101\\nAgents, supercharged - Multi-agents, External tools, and more\\nGeneration with LLMs\\nChatting with Transformers\\n\\n\\nTask Guides\\n\\n\\n\\nNatural Language Processing\\n\\n\\nAudio\\n\\n\\nComputer Vision\\n\\n\\nMultimodal\\n\\n\\nGeneration\\n\\n\\nPrompting\\n\\n\\n\\nDeveloper guides\\n\\n\\nUse fast tokenizers from ğŸ¤— Tokenizers\\nRun inference with multilingual models\\nUse model-specific APIs\\nShare a custom model\\nChat templates\\nTrainer\\nRun training on Amazon SageMaker\\nExport to ONNX\\nExport to TFLite\\nExport to TorchScript\\nBenchmarks\\nNotebooks with examples\\nCommunity resources\\nTroubleshoot\\nInteroperability with GGUF files\\nInteroperability with TikToken files\\nModularity in `transformers`\\nModel Hacking (overwriting a class to your usage)\\n\\n\\nQuantization Methods\\n\\n\\nGetting started\\nbitsandbytes\\nGPTQ\\nAWQ\\nAQLM\\nVPTQ\\nQuanto\\nEETQ\\nHIGGS\\nHQQ\\nFBGEMM_FP8\\nOptimum\\nTorchAO\\nBitNet\\ncompressed-tensors\\nContribute new quantization method\\n\\n\\nPerformance and scalability\\n\\n\\nOverview\\nLLM inference optimization\\n\\nEfficient training techniques\\n\\n\\nMethods and tools for efficient training on a single GPU\\nMultiple GPUs and parallelism\\nFully Sharded Data Parallel\\nDeepSpeed\\nEfficient training on CPU\\nDistributed CPU training\\nTraining on TPU with TensorFlow\\nPyTorch training on Apple silicon\\nCustom hardware for training\\nHyperparameter Search using Trainer API\\n\\n\\nOptimizing inference\\n\\n\\nCPU inference\\nGPU inference\\nMulti-GPU inference\\n\\nInstantiate a big model\\nDebugging\\nXLA Integration for TensorFlow Models\\nOptimize inference using `torch.compile()`\\n\\n\\nContribute\\n\\n\\nHow to contribute to ğŸ¤— Transformers?\\nHow to add a model to ğŸ¤— Transformers?\\nHow to add a pipeline to ğŸ¤— Transformers?\\nTesting\\nChecks on a Pull Request\\n\\n\\nConceptual guides\\n\\n\\nPhilosophy\\nGlossary\\nWhat ğŸ¤— Transformers can do\\nHow ğŸ¤— Transformers solve tasks\\nThe Transformer model family\\nSummary of the tokenizers\\nAttention mechanisms\\nPadding and truncation\\nBERTology\\nPerplexity of fixed-length models\\nPipelines for webserver inference\\nModel training anatomy\\nGetting the most out of LLMs\\n\\n\\nAPI\\n\\n\\n\\nMain Classes\\n\\n\\nAgents and Tools\\nAuto Classes\\nBackbones\\nCallbacks\\nConfiguration\\nData Collator\\nKeras callbacks\\nLogging\\nModels\\nText Generation\\nONNX\\nOptimization\\nModel outputs\\nPipelines\\nProcessors\\nQuantization\\nTokenizer\\nTrainer\\nDeepSpeed\\nExecuTorch\\nFeature Extractor\\nImage Processor\\n\\n\\nModels\\n\\n\\n\\nText models\\n\\n\\nVision models\\n\\n\\nAudio models\\n\\n\\nVideo models\\n\\n\\nMultimodal models\\n\\n\\nReinforcement learning models\\n\\n\\nTime series models\\n\\n\\nGraph models\\n\\n\\n\\nInternal Helpers\\n\\n\\nCustom Layers and Utilities\\nUtilities for pipelines\\nUtilities for Tokenizers\\nUtilities for Trainer\\nUtilities for Generation\\nUtilities for Image Processors\\nUtilities for Audio processing\\nGeneral Utilities\\nUtilities for Time Series\\n\\n\\n\\n\\n\\nJoin the Hugging Face community\\nand get access to the augmented documentation experience\\n\\t\\t\\n\\nCollaborate on models, datasets and Spaces\\n\\t\\t\\t\\t\\n\\nFaster examples with accelerated inference\\n\\t\\t\\t\\t\\n\\nSwitch between documentation themes\\n\\t\\t\\t\\t\\nSign Up\\nto get started\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n   ğŸ¤— Transformers State-of-the-art Machine Learning for PyTorch, TensorFlow, and JAX. ğŸ¤— Transformers provides APIs and tools to easily download and train state-of-the-art pretrained models. Using pretrained models can reduce your compute costs, carbon footprint, and save you the time and resources required to train a model from scratch. These models support common tasks in different modalities, such as: ğŸ“ Natural Language Processing: text classification, named entity recognition, question answering, language modeling, code generation, summarization, translation, multiple choice, and text generation.\\nğŸ–¼ï¸ Computer Vision: image classification, object detection, and segmentation.\\nğŸ—£ï¸ Audio: automatic speech recognition and audio classification.\\nğŸ™ Multimodal: table question answering, optical character recognition, information extraction from scanned documents, video classification, and visual question answering. ğŸ¤— Transformers support framework interoperability between PyTorch, TensorFlow, and JAX. This provides the flexibility to use a different framework at each stage of a modelâ€™s life; train a model in three lines of code in one framework, and load it for inference in another. Models can also be exported to a format like ONNX and TorchScript for deployment in production environments. Join the growing community on the Hub, forum, or Discord today!  If you are looking for custom support from the Hugging Face team   Contents The documentation is organized into five sections: GET STARTED provides a quick tour of the library and installation instructions to get up and running. TUTORIALS are a great place to start if youâ€™re a beginner. This section will help you gain the basic skills you need to start using the library. HOW-TO GUIDES show you how to achieve a specific goal, like finetuning a pretrained model for language modeling or how to write and share a custom model. CONCEPTUAL GUIDES offers more discussion and explanation of the underlying concepts and ideas behind models, tasks, and the design philosophy of ğŸ¤— Transformers. API describes all classes and functions: MAIN CLASSES details the most important classes like configuration, model, tokenizer, and pipeline. MODELS details the classes and functions related to each model implemented in the library. INTERNAL HELPERS details utility classes and functions used internally.  Supported models and frameworks The table below represents the current support in the library for each of those models, whether they have a Python\\ntokenizer (called â€œslowâ€). A â€œfastâ€ tokenizer backed by the ğŸ¤— Tokenizers library, whether they have support in Jax (via\\nFlax), PyTorch, and/or TensorFlow. Model PyTorch support TensorFlow support Flax Support ALBERT âœ… âœ… âœ… ALIGN âœ… âŒ âŒ AltCLIP âœ… âŒ âŒ Aria âœ… âŒ âŒ AriaText âœ… âŒ âŒ Audio Spectrogram Transformer âœ… âŒ âŒ Autoformer âœ… âŒ âŒ Bamba âœ… âŒ âŒ Bark âœ… âŒ âŒ BART âœ… âœ… âœ… BARThez âœ… âœ… âœ… BARTpho âœ… âœ… âœ… BEiT âœ… âŒ âœ… BERT âœ… âœ… âœ… Bert Generation âœ… âŒ âŒ BertJapanese âœ… âœ… âœ… BERTweet âœ… âœ… âœ… BigBird âœ… âŒ âœ… BigBird-Pegasus âœ… âŒ âŒ BioGpt âœ… âŒ âŒ BiT âœ… âŒ âŒ Blenderbot âœ… âœ… âœ… BlenderbotSmall âœ… âœ… âœ… BLIP âœ… âœ… âŒ BLIP-2 âœ… âŒ âŒ BLOOM âœ… âŒ âœ… BORT âœ… âœ… âœ… BridgeTower âœ… âŒ âŒ BROS âœ… âŒ âŒ ByT5 âœ… âœ… âœ… CamemBERT âœ… âœ… âŒ CANINE âœ… âŒ âŒ Chameleon âœ… âŒ âŒ Chinese-CLIP âœ… âŒ âŒ CLAP âœ… âŒ âŒ CLIP âœ… âœ… âœ… CLIPSeg âœ… âŒ âŒ CLVP âœ… âŒ âŒ CodeGen âœ… âŒ âŒ CodeLlama âœ… âŒ âœ… Cohere âœ… âŒ âŒ Cohere2 âœ… âŒ âŒ ColPali âœ… âŒ âŒ Conditional DETR âœ… âŒ âŒ ConvBERT âœ… âœ… âŒ ConvNeXT âœ… âœ… âŒ ConvNeXTV2 âœ… âœ… âŒ CPM âœ… âœ… âœ… CPM-Ant âœ… âŒ âŒ CTRL âœ… âœ… âŒ CvT âœ… âœ… âŒ DAC âœ… âŒ âŒ Data2VecAudio âœ… âŒ âŒ Data2VecText âœ… âŒ âŒ Data2VecVision âœ… âœ… âŒ DBRX âœ… âŒ âŒ DeBERTa âœ… âœ… âŒ DeBERTa-v2 âœ… âœ… âŒ Decision Transformer âœ… âŒ âŒ Deformable DETR âœ… âŒ âŒ DeiT âœ… âœ… âŒ DePlot âœ… âŒ âŒ Depth Anything âœ… âŒ âŒ DETA âœ… âŒ âŒ DETR âœ… âŒ âŒ DialoGPT âœ… âœ… âœ… DiffLlama âœ… âŒ âŒ DiNAT âœ… âŒ âŒ DINOv2 âœ… âŒ âœ… DINOv2 with Registers âœ… âŒ âŒ DistilBERT âœ… âœ… âœ… DiT âœ… âŒ âœ… DonutSwin âœ… âŒ âŒ DPR âœ… âœ… âŒ DPT âœ… âŒ âŒ EfficientFormer âœ… âœ… âŒ EfficientNet âœ… âŒ âŒ ELECTRA âœ… âœ… âœ… Emu3 âœ… âŒ âŒ EnCodec âœ… âŒ âŒ Encoder decoder âœ… âœ… âœ… ERNIE âœ… âŒ âŒ ErnieM âœ… âŒ âŒ ESM âœ… âœ… âŒ FairSeq Machine-Translation âœ… âŒ âŒ Falcon âœ… âŒ âŒ Falcon3 âœ… âŒ âœ… FalconMamba âœ… âŒ âŒ FastSpeech2Conformer âœ… âŒ âŒ FLAN-T5 âœ… âœ… âœ… FLAN-UL2 âœ… âœ… âœ… FlauBERT âœ… âœ… âŒ FLAVA âœ… âŒ âŒ FNet âœ… âŒ âŒ FocalNet âœ… âŒ âŒ Funnel Transformer âœ… âœ… âŒ Fuyu âœ… âŒ âŒ Gemma âœ… âŒ âœ… Gemma2 âœ… âŒ âŒ GIT âœ… âŒ âŒ GLM âœ… âŒ âŒ GLPN âœ… âŒ âŒ GPT Neo âœ… âŒ âœ… GPT NeoX âœ… âŒ âŒ GPT NeoX Japanese âœ… âŒ âŒ GPT-J âœ… âœ… âœ… GPT-Sw3 âœ… âœ… âœ… GPTBigCode âœ… âŒ âŒ GPTSAN-japanese âœ… âŒ âŒ Granite âœ… âŒ âŒ GraniteMoeMoe âœ… âŒ âŒ Graphormer âœ… âŒ âŒ Grounding DINO âœ… âŒ âŒ GroupViT âœ… âœ… âŒ HerBERT âœ… âœ… âœ… Hiera âœ… âŒ âŒ Hubert âœ… âœ… âŒ I-BERT âœ… âŒ âŒ I-JEPA âœ… âŒ âŒ IDEFICS âœ… âœ… âŒ Idefics2 âœ… âŒ âŒ Idefics3 âœ… âŒ âŒ Idefics3VisionTransformer âŒ âŒ âŒ ImageGPT âœ… âŒ âŒ Informer âœ… âŒ âŒ InstructBLIP âœ… âŒ âŒ InstructBlipVideo âœ… âŒ âŒ Jamba âœ… âŒ âŒ JetMoe âœ… âŒ âŒ Jukebox âœ… âŒ âŒ KOSMOS-2 âœ… âŒ âŒ LayoutLM âœ… âœ… âŒ LayoutLMv2 âœ… âŒ âŒ LayoutLMv3 âœ… âœ… âŒ LayoutXLM âœ… âŒ âŒ LED âœ… âœ… âŒ LeViT âœ… âŒ âŒ LiLT âœ… âŒ âŒ LLaMA âœ… âŒ âœ… Llama2 âœ… âŒ âœ… Llama3 âœ… âŒ âœ… LLaVa âœ… âŒ âŒ LLaVA-NeXT âœ… âŒ âŒ LLaVa-NeXT-Video âœ… âŒ âŒ LLaVA-Onevision âœ… âŒ âŒ Longformer âœ… âœ… âŒ LongT5 âœ… âŒ âœ… LUKE âœ… âŒ âŒ LXMERT âœ… âœ… âŒ M-CTC-T âœ… âŒ âŒ M2M100 âœ… âŒ âŒ MADLAD-400 âœ… âœ… âœ… Mamba âœ… âŒ âŒ mamba2 âœ… âŒ âŒ Marian âœ… âœ… âœ… MarkupLM âœ… âŒ âŒ Mask2Former âœ… âŒ âŒ MaskFormer âœ… âŒ âŒ MatCha âœ… âŒ âŒ mBART âœ… âœ… âœ… mBART-50 âœ… âœ… âœ… MEGA âœ… âŒ âŒ Megatron-BERT âœ… âŒ âŒ Megatron-GPT2 âœ… âœ… âœ… MGP-STR âœ… âŒ âŒ Mimi âœ… âŒ âŒ Mistral âœ… âœ… âœ… Mixtral âœ… âŒ âŒ Mllama âœ… âŒ âŒ mLUKE âœ… âŒ âŒ MMS âœ… âœ… âœ… MobileBERT âœ… âœ… âŒ MobileNetV1 âœ… âŒ âŒ MobileNetV2 âœ… âŒ âŒ MobileViT âœ… âœ… âŒ MobileViTV2 âœ… âŒ âŒ ModernBERT âœ… âŒ âŒ Moonshine âœ… âŒ âŒ Moshi âœ… âŒ âŒ MPNet âœ… âœ… âŒ MPT âœ… âŒ âŒ MRA âœ… âŒ âŒ MT5 âœ… âœ… âœ… MusicGen âœ… âŒ âŒ MusicGen Melody âœ… âŒ âŒ MVP âœ… âŒ âŒ NAT âœ… âŒ âŒ Nemotron âœ… âŒ âŒ Nezha âœ… âŒ âŒ NLLB âœ… âŒ âŒ NLLB-MOE âœ… âŒ âŒ Nougat âœ… âœ… âœ… NystrÃ¶mformer âœ… âŒ âŒ OLMo âœ… âŒ âŒ OLMo2 âœ… âŒ âŒ OLMoE âœ… âŒ âŒ OmDet-Turbo âœ… âŒ âŒ OneFormer âœ… âŒ âŒ OpenAI GPT âœ… âœ… âŒ OpenAI GPT-2 âœ… âœ… âœ… OpenLlama âœ… âŒ âŒ OPT âœ… âœ… âœ… OWL-ViT âœ… âŒ âŒ OWLv2 âœ… âŒ âŒ PaliGemma âœ… âŒ âŒ PatchTSMixer âœ… âŒ âŒ PatchTST âœ… âŒ âŒ Pegasus âœ… âœ… âœ… PEGASUS-X âœ… âŒ âŒ Perceiver âœ… âŒ âŒ Persimmon âœ… âŒ âŒ Phi âœ… âŒ âŒ Phi3 âœ… âŒ âŒ Phimoe âœ… âŒ âŒ PhoBERT âœ… âœ… âœ… Pix2Struct âœ… âŒ âŒ Pixtral âœ… âŒ âŒ PLBart âœ… âŒ âŒ PoolFormer âœ… âŒ âŒ Pop2Piano âœ… âŒ âŒ ProphetNet âœ… âŒ âŒ PVT âœ… âŒ âŒ PVTv2 âœ… âŒ âŒ QDQBert âœ… âŒ âŒ Qwen2 âœ… âŒ âŒ Qwen2Audio âœ… âŒ âŒ Qwen2MoE âœ… âŒ âŒ Qwen2VL âœ… âŒ âŒ RAG âœ… âœ… âŒ REALM âœ… âŒ âŒ RecurrentGemma âœ… âŒ âŒ Reformer âœ… âŒ âŒ RegNet âœ… âœ… âœ… RemBERT âœ… âœ… âŒ ResNet âœ… âœ… âœ… RetriBERT âœ… âŒ âŒ RoBERTa âœ… âœ… âœ… RoBERTa-PreLayerNorm âœ… âœ… âœ… RoCBert âœ… âŒ âŒ RoFormer âœ… âœ… âœ… RT-DETR âœ… âŒ âŒ RT-DETR-ResNet âœ… âŒ âŒ RWKV âœ… âŒ âŒ SAM âœ… âœ… âŒ SeamlessM4T âœ… âŒ âŒ SeamlessM4Tv2 âœ… âŒ âŒ SegFormer âœ… âœ… âŒ SegGPT âœ… âŒ âŒ SEW âœ… âŒ âŒ SEW-D âœ… âŒ âŒ SigLIP âœ… âŒ âŒ Speech Encoder decoder âœ… âŒ âœ… Speech2Text âœ… âœ… âŒ SpeechT5 âœ… âŒ âŒ Splinter âœ… âŒ âŒ SqueezeBERT âœ… âŒ âŒ StableLm âœ… âŒ âŒ Starcoder2 âœ… âŒ âŒ SuperPoint âœ… âŒ âŒ SwiftFormer âœ… âœ… âŒ Swin Transformer âœ… âœ… âŒ Swin Transformer V2 âœ… âŒ âŒ Swin2SR âœ… âŒ âŒ SwitchTransformers âœ… âŒ âŒ T5 âœ… âœ… âœ… T5v1.1 âœ… âœ… âœ… Table Transformer âœ… âŒ âŒ TAPAS âœ… âœ… âŒ TAPEX âœ… âœ… âœ… TextNet âœ… âŒ âŒ Time Series Transformer âœ… âŒ âŒ TimeSformer âœ… âŒ âŒ TimmWrapperModel âœ… âŒ âŒ Trajectory Transformer âœ… âŒ âŒ Transformer-XL âœ… âœ… âŒ TrOCR âœ… âŒ âŒ TVLT âœ… âŒ âŒ TVP âœ… âŒ âŒ UDOP âœ… âŒ âŒ UL2 âœ… âœ… âœ… UMT5 âœ… âŒ âŒ UniSpeech âœ… âŒ âŒ UniSpeechSat âœ… âŒ âŒ UnivNet âœ… âŒ âŒ UPerNet âœ… âŒ âŒ VAN âœ… âŒ âŒ VideoLlava âœ… âŒ âŒ VideoMAE âœ… âŒ âŒ ViLT âœ… âŒ âŒ VipLlava âœ… âŒ âŒ Vision Encoder decoder âœ… âœ… âœ… VisionTextDualEncoder âœ… âœ… âœ… VisualBERT âœ… âŒ âŒ ViT âœ… âœ… âœ… ViT Hybrid âœ… âŒ âŒ VitDet âœ… âŒ âŒ ViTMAE âœ… âœ… âŒ ViTMatte âœ… âŒ âŒ ViTMSN âœ… âŒ âŒ VitPose âœ… âŒ âŒ VitPoseBackbone âœ… âŒ âŒ VITS âœ… âŒ âŒ ViViT âœ… âŒ âŒ Wav2Vec2 âœ… âœ… âœ… Wav2Vec2-BERT âœ… âŒ âŒ Wav2Vec2-Conformer âœ… âŒ âŒ Wav2Vec2Phoneme âœ… âœ… âœ… WavLM âœ… âŒ âŒ Whisper âœ… âœ… âœ… X-CLIP âœ… âŒ âŒ X-MOD âœ… âŒ âŒ XGLM âœ… âœ… âœ… XLM âœ… âœ… âŒ XLM-ProphetNet âœ… âŒ âŒ XLM-RoBERTa âœ… âœ… âœ… XLM-RoBERTa-XL âœ… âŒ âŒ XLM-V âœ… âœ… âœ… XLNet âœ… âœ… âŒ XLS-R âœ… âœ… âœ… XLSR-Wav2Vec2 âœ… âœ… âœ… YOLOS âœ… âŒ âŒ YOSO âœ… âŒ âŒ Zamba âœ… âŒ âŒ ZoeDepth âœ… âŒ âŒ < > Update on GitHub \\n\\n\\n\\nQuick tourâ†’\\n\\n\\nğŸ¤— Transformers\\nIf you are looking for custom support from the Hugging Face team\\nContents\\nSupported models and frameworks\\n\\n\\n\\n\\n\\n\\n\\n\\n')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "loader = WebBaseLoader(\"https://huggingface.co/docs/transformers/index\")\n",
    "docs = loader.load()\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://huggingface.co/docs/transformers/index', 'title': 'ğŸ¤— Transformers', 'description': 'Weâ€™re on a journey to advance and democratize artificial intelligence through open source and open science.', 'language': 'No language found.'}, page_content='ğŸ¤— Transformers\\n\\n\\n\\n\\n\\n\\n\\n\\nHugging Face\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\t\\t\\tModels\\n\\n\\t\\t\\t\\t\\tDatasets\\n\\n\\t\\t\\t\\t\\tSpaces\\n\\n\\t\\t\\t\\t\\tPosts\\n\\n\\t\\t\\t\\t\\tDocs\\n\\n\\t\\t\\t\\t\\tEnterprise\\n\\nPricing\\n\\t\\t\\t\\n\\n\\n\\n\\n\\n\\nLog In\\n\\t\\t\\t\\t\\nSign Up\\n\\t\\t\\t\\t\\t\\n\\n\\n\\nTransformers documentation\\n\\t\\t\\t\\nğŸ¤— Transformers\\n\\n\\n\\nTransformers\\n\\nğŸ¡ View all docsAWS Trainium & InferentiaAccelerateAmazon SageMakerArgillaAutoTrainBitsandbytesChat UICompetitionsDataset viewerDatasetsDiffusersDistilabelEvaluateGoogle CloudGoogle TPUsGradioHubHub Python LibraryHugging Face Generative AI Services (HUGS)Huggingface.jsInference API (serverless)Inference Endpoints (dedicated)LeaderboardsLightevalOptimumPEFTSafetensorsSentence TransformersTRLTasksText Embeddings InferenceText Generation InferenceTokenizersTransformersTransformers.jssmolagentstimm\\n\\nSearch documentation'),\n",
       " Document(metadata={'source': 'https://huggingface.co/docs/transformers/index', 'title': 'ğŸ¤— Transformers', 'description': 'Weâ€™re on a journey to advance and democratize artificial intelligence through open source and open science.', 'language': 'No language found.'}, page_content='Search documentation\\n\\n\\nmainv4.48.0v4.47.1v4.46.3v4.45.2v4.44.2v4.43.4v4.42.4v4.41.2v4.40.2v4.39.3v4.38.2v4.37.2v4.36.1v4.35.2v4.34.1v4.33.3v4.32.1v4.31.0v4.30.0v4.29.1v4.28.1v4.27.2v4.26.1v4.25.1v4.24.0v4.23.1v4.22.2v4.21.3v4.20.1v4.19.4v4.18.0v4.17.0v4.16.2v4.15.0v4.14.1v4.13.0v4.12.5v4.11.3v4.10.1v4.9.2v4.8.2v4.7.0v4.6.0v4.5.1v4.4.2v4.3.3v4.2.2v4.1.1v4.0.1v3.5.1v3.4.0v3.3.1v3.2.0v3.1.0v3.0.2v2.11.0v2.10.0v2.9.1v2.8.0v2.7.0v2.6.0v2.5.1v2.4.1v2.3.0v2.2.2v2.1.1v2.0.0v1.2.0v1.1.0v1.0.0doc-builder-html\\nARDEENESFRHIITJAKOPTTETRZH\\n\\n\\n\\n\\n\\n\\n\\n\\nGet started\\n\\n\\nğŸ¤— Transformers\\nQuick tour\\nInstallation\\nAdding a new model to `transformers`\\n\\n\\nTutorials\\n\\n\\nRun inference with pipelines\\nWrite portable code with AutoClass\\nPreprocess data\\nFine-tune a pretrained model\\nTrain with a script\\nSet up distributed training with ğŸ¤— Accelerate\\nLoad and train adapters with ğŸ¤— PEFT\\nShare your model\\nAgents 101\\nAgents, supercharged - Multi-agents, External tools, and more\\nGeneration with LLMs\\nChatting with Transformers'),\n",
       " Document(metadata={'source': 'https://huggingface.co/docs/transformers/index', 'title': 'ğŸ¤— Transformers', 'description': 'Weâ€™re on a journey to advance and democratize artificial intelligence through open source and open science.', 'language': 'No language found.'}, page_content='Task Guides\\n\\n\\n\\nNatural Language Processing\\n\\n\\nAudio\\n\\n\\nComputer Vision\\n\\n\\nMultimodal\\n\\n\\nGeneration\\n\\n\\nPrompting\\n\\n\\n\\nDeveloper guides\\n\\n\\nUse fast tokenizers from ğŸ¤— Tokenizers\\nRun inference with multilingual models\\nUse model-specific APIs\\nShare a custom model\\nChat templates\\nTrainer\\nRun training on Amazon SageMaker\\nExport to ONNX\\nExport to TFLite\\nExport to TorchScript\\nBenchmarks\\nNotebooks with examples\\nCommunity resources\\nTroubleshoot\\nInteroperability with GGUF files\\nInteroperability with TikToken files\\nModularity in `transformers`\\nModel Hacking (overwriting a class to your usage)\\n\\n\\nQuantization Methods\\n\\n\\nGetting started\\nbitsandbytes\\nGPTQ\\nAWQ\\nAQLM\\nVPTQ\\nQuanto\\nEETQ\\nHIGGS\\nHQQ\\nFBGEMM_FP8\\nOptimum\\nTorchAO\\nBitNet\\ncompressed-tensors\\nContribute new quantization method\\n\\n\\nPerformance and scalability\\n\\n\\nOverview\\nLLM inference optimization\\n\\nEfficient training techniques'),\n",
       " Document(metadata={'source': 'https://huggingface.co/docs/transformers/index', 'title': 'ğŸ¤— Transformers', 'description': 'Weâ€™re on a journey to advance and democratize artificial intelligence through open source and open science.', 'language': 'No language found.'}, page_content='Performance and scalability\\n\\n\\nOverview\\nLLM inference optimization\\n\\nEfficient training techniques\\n\\n\\nMethods and tools for efficient training on a single GPU\\nMultiple GPUs and parallelism\\nFully Sharded Data Parallel\\nDeepSpeed\\nEfficient training on CPU\\nDistributed CPU training\\nTraining on TPU with TensorFlow\\nPyTorch training on Apple silicon\\nCustom hardware for training\\nHyperparameter Search using Trainer API\\n\\n\\nOptimizing inference\\n\\n\\nCPU inference\\nGPU inference\\nMulti-GPU inference\\n\\nInstantiate a big model\\nDebugging\\nXLA Integration for TensorFlow Models\\nOptimize inference using `torch.compile()`\\n\\n\\nContribute\\n\\n\\nHow to contribute to ğŸ¤— Transformers?\\nHow to add a model to ğŸ¤— Transformers?\\nHow to add a pipeline to ğŸ¤— Transformers?\\nTesting\\nChecks on a Pull Request\\n\\n\\nConceptual guides'),\n",
       " Document(metadata={'source': 'https://huggingface.co/docs/transformers/index', 'title': 'ğŸ¤— Transformers', 'description': 'Weâ€™re on a journey to advance and democratize artificial intelligence through open source and open science.', 'language': 'No language found.'}, page_content='Contribute\\n\\n\\nHow to contribute to ğŸ¤— Transformers?\\nHow to add a model to ğŸ¤— Transformers?\\nHow to add a pipeline to ğŸ¤— Transformers?\\nTesting\\nChecks on a Pull Request\\n\\n\\nConceptual guides\\n\\n\\nPhilosophy\\nGlossary\\nWhat ğŸ¤— Transformers can do\\nHow ğŸ¤— Transformers solve tasks\\nThe Transformer model family\\nSummary of the tokenizers\\nAttention mechanisms\\nPadding and truncation\\nBERTology\\nPerplexity of fixed-length models\\nPipelines for webserver inference\\nModel training anatomy\\nGetting the most out of LLMs\\n\\n\\nAPI\\n\\n\\n\\nMain Classes\\n\\n\\nAgents and Tools\\nAuto Classes\\nBackbones\\nCallbacks\\nConfiguration\\nData Collator\\nKeras callbacks\\nLogging\\nModels\\nText Generation\\nONNX\\nOptimization\\nModel outputs\\nPipelines\\nProcessors\\nQuantization\\nTokenizer\\nTrainer\\nDeepSpeed\\nExecuTorch\\nFeature Extractor\\nImage Processor\\n\\n\\nModels\\n\\n\\n\\nText models\\n\\n\\nVision models\\n\\n\\nAudio models\\n\\n\\nVideo models\\n\\n\\nMultimodal models\\n\\n\\nReinforcement learning models\\n\\n\\nTime series models\\n\\n\\nGraph models\\n\\n\\n\\nInternal Helpers'),\n",
       " Document(metadata={'source': 'https://huggingface.co/docs/transformers/index', 'title': 'ğŸ¤— Transformers', 'description': 'Weâ€™re on a journey to advance and democratize artificial intelligence through open source and open science.', 'language': 'No language found.'}, page_content='Models\\n\\n\\n\\nText models\\n\\n\\nVision models\\n\\n\\nAudio models\\n\\n\\nVideo models\\n\\n\\nMultimodal models\\n\\n\\nReinforcement learning models\\n\\n\\nTime series models\\n\\n\\nGraph models\\n\\n\\n\\nInternal Helpers\\n\\n\\nCustom Layers and Utilities\\nUtilities for pipelines\\nUtilities for Tokenizers\\nUtilities for Trainer\\nUtilities for Generation\\nUtilities for Image Processors\\nUtilities for Audio processing\\nGeneral Utilities\\nUtilities for Time Series\\n\\n\\n\\n\\n\\nJoin the Hugging Face community\\nand get access to the augmented documentation experience\\n\\t\\t\\n\\nCollaborate on models, datasets and Spaces\\n\\t\\t\\t\\t\\n\\nFaster examples with accelerated inference\\n\\t\\t\\t\\t\\n\\nSwitch between documentation themes\\n\\t\\t\\t\\t\\nSign Up\\nto get started'),\n",
       " Document(metadata={'source': 'https://huggingface.co/docs/transformers/index', 'title': 'ğŸ¤— Transformers', 'description': 'Weâ€™re on a journey to advance and democratize artificial intelligence through open source and open science.', 'language': 'No language found.'}, page_content='ğŸ¤— Transformers State-of-the-art Machine Learning for PyTorch, TensorFlow, and JAX. ğŸ¤— Transformers provides APIs and tools to easily download and train state-of-the-art pretrained models. Using pretrained models can reduce your compute costs, carbon footprint, and save you the time and resources required to train a model from scratch. These models support common tasks in different modalities, such as: ğŸ“ Natural Language Processing: text classification, named entity recognition, question answering, language modeling, code generation, summarization, translation, multiple choice, and text generation.\\nğŸ–¼ï¸ Computer Vision: image classification, object detection, and segmentation.\\nğŸ—£ï¸ Audio: automatic speech recognition and audio classification.'),\n",
       " Document(metadata={'source': 'https://huggingface.co/docs/transformers/index', 'title': 'ğŸ¤— Transformers', 'description': 'Weâ€™re on a journey to advance and democratize artificial intelligence through open source and open science.', 'language': 'No language found.'}, page_content='ğŸ™ Multimodal: table question answering, optical character recognition, information extraction from scanned documents, video classification, and visual question answering. ğŸ¤— Transformers support framework interoperability between PyTorch, TensorFlow, and JAX. This provides the flexibility to use a different framework at each stage of a modelâ€™s life; train a model in three lines of code in one framework, and load it for inference in another. Models can also be exported to a format like ONNX and TorchScript for deployment in production environments. Join the growing community on the Hub, forum, or Discord today!  If you are looking for custom support from the Hugging Face team   Contents The documentation is organized into five sections: GET STARTED provides a quick tour of the library and installation instructions to get up and running. TUTORIALS are a great place to start if youâ€™re a beginner. This section will help you gain the basic skills you need to start using the library. HOW-TO'),\n",
       " Document(metadata={'source': 'https://huggingface.co/docs/transformers/index', 'title': 'ğŸ¤— Transformers', 'description': 'Weâ€™re on a journey to advance and democratize artificial intelligence through open source and open science.', 'language': 'No language found.'}, page_content='instructions to get up and running. TUTORIALS are a great place to start if youâ€™re a beginner. This section will help you gain the basic skills you need to start using the library. HOW-TO GUIDES show you how to achieve a specific goal, like finetuning a pretrained model for language modeling or how to write and share a custom model. CONCEPTUAL GUIDES offers more discussion and explanation of the underlying concepts and ideas behind models, tasks, and the design philosophy of ğŸ¤— Transformers. API describes all classes and functions: MAIN CLASSES details the most important classes like configuration, model, tokenizer, and pipeline. MODELS details the classes and functions related to each model implemented in the library. INTERNAL HELPERS details utility classes and functions used internally.  Supported models and frameworks The table below represents the current support in the library for each of those models, whether they have a Python'),\n",
       " Document(metadata={'source': 'https://huggingface.co/docs/transformers/index', 'title': 'ğŸ¤— Transformers', 'description': 'Weâ€™re on a journey to advance and democratize artificial intelligence through open source and open science.', 'language': 'No language found.'}, page_content='tokenizer (called â€œslowâ€). A â€œfastâ€ tokenizer backed by the ğŸ¤— Tokenizers library, whether they have support in Jax (via'),\n",
       " Document(metadata={'source': 'https://huggingface.co/docs/transformers/index', 'title': 'ğŸ¤— Transformers', 'description': 'Weâ€™re on a journey to advance and democratize artificial intelligence through open source and open science.', 'language': 'No language found.'}, page_content='Flax), PyTorch, and/or TensorFlow. Model PyTorch support TensorFlow support Flax Support ALBERT âœ… âœ… âœ… ALIGN âœ… âŒ âŒ AltCLIP âœ… âŒ âŒ Aria âœ… âŒ âŒ AriaText âœ… âŒ âŒ Audio Spectrogram Transformer âœ… âŒ âŒ Autoformer âœ… âŒ âŒ Bamba âœ… âŒ âŒ Bark âœ… âŒ âŒ BART âœ… âœ… âœ… BARThez âœ… âœ… âœ… BARTpho âœ… âœ… âœ… BEiT âœ… âŒ âœ… BERT âœ… âœ… âœ… Bert Generation âœ… âŒ âŒ BertJapanese âœ… âœ… âœ… BERTweet âœ… âœ… âœ… BigBird âœ… âŒ âœ… BigBird-Pegasus âœ… âŒ âŒ BioGpt âœ… âŒ âŒ BiT âœ… âŒ âŒ Blenderbot âœ… âœ… âœ… BlenderbotSmall âœ… âœ… âœ… BLIP âœ… âœ… âŒ BLIP-2 âœ… âŒ âŒ BLOOM âœ… âŒ âœ… BORT âœ… âœ… âœ… BridgeTower âœ… âŒ âŒ BROS âœ… âŒ âŒ ByT5 âœ… âœ… âœ… CamemBERT âœ… âœ… âŒ CANINE âœ… âŒ âŒ Chameleon âœ… âŒ âŒ Chinese-CLIP âœ… âŒ âŒ CLAP âœ… âŒ âŒ CLIP âœ… âœ… âœ… CLIPSeg âœ… âŒ âŒ CLVP âœ… âŒ âŒ CodeGen âœ… âŒ âŒ CodeLlama âœ… âŒ âœ… Cohere âœ… âŒ âŒ Cohere2 âœ… âŒ âŒ ColPali âœ… âŒ âŒ Conditional DETR âœ… âŒ âŒ ConvBERT âœ… âœ… âŒ ConvNeXT âœ… âœ… âŒ ConvNeXTV2 âœ… âœ… âŒ CPM âœ… âœ… âœ… CPM-Ant âœ… âŒ âŒ CTRL âœ… âœ… âŒ CvT âœ… âœ… âŒ DAC âœ… âŒ âŒ Data2VecAudio âœ… âŒ âŒ Data2VecText âœ… âŒ âŒ Data2VecVision âœ… âœ… âŒ DBRX âœ… âŒ âŒ DeBERTa âœ… âœ… âŒ DeBERTa-v2 âœ… âœ… âŒ Decision Transformer âœ… âŒ âŒ Deformable DETR âœ… âŒ âŒ DeiT âœ… âœ…'),\n",
       " Document(metadata={'source': 'https://huggingface.co/docs/transformers/index', 'title': 'ğŸ¤— Transformers', 'description': 'Weâ€™re on a journey to advance and democratize artificial intelligence through open source and open science.', 'language': 'No language found.'}, page_content='âœ… âŒ âŒ CTRL âœ… âœ… âŒ CvT âœ… âœ… âŒ DAC âœ… âŒ âŒ Data2VecAudio âœ… âŒ âŒ Data2VecText âœ… âŒ âŒ Data2VecVision âœ… âœ… âŒ DBRX âœ… âŒ âŒ DeBERTa âœ… âœ… âŒ DeBERTa-v2 âœ… âœ… âŒ Decision Transformer âœ… âŒ âŒ Deformable DETR âœ… âŒ âŒ DeiT âœ… âœ… âŒ DePlot âœ… âŒ âŒ Depth Anything âœ… âŒ âŒ DETA âœ… âŒ âŒ DETR âœ… âŒ âŒ DialoGPT âœ… âœ… âœ… DiffLlama âœ… âŒ âŒ DiNAT âœ… âŒ âŒ DINOv2 âœ… âŒ âœ… DINOv2 with Registers âœ… âŒ âŒ DistilBERT âœ… âœ… âœ… DiT âœ… âŒ âœ… DonutSwin âœ… âŒ âŒ DPR âœ… âœ… âŒ DPT âœ… âŒ âŒ EfficientFormer âœ… âœ… âŒ EfficientNet âœ… âŒ âŒ ELECTRA âœ… âœ… âœ… Emu3 âœ… âŒ âŒ EnCodec âœ… âŒ âŒ Encoder decoder âœ… âœ… âœ… ERNIE âœ… âŒ âŒ ErnieM âœ… âŒ âŒ ESM âœ… âœ… âŒ FairSeq Machine-Translation âœ… âŒ âŒ Falcon âœ… âŒ âŒ Falcon3 âœ… âŒ âœ… FalconMamba âœ… âŒ âŒ FastSpeech2Conformer âœ… âŒ âŒ FLAN-T5 âœ… âœ… âœ… FLAN-UL2 âœ… âœ… âœ… FlauBERT âœ… âœ… âŒ FLAVA âœ… âŒ âŒ FNet âœ… âŒ âŒ FocalNet âœ… âŒ âŒ Funnel Transformer âœ… âœ… âŒ Fuyu âœ… âŒ âŒ Gemma âœ… âŒ âœ… Gemma2 âœ… âŒ âŒ GIT âœ… âŒ âŒ GLM âœ… âŒ âŒ GLPN âœ… âŒ âŒ GPT Neo âœ… âŒ âœ… GPT NeoX âœ… âŒ âŒ GPT NeoX Japanese âœ… âŒ âŒ GPT-J âœ… âœ… âœ… GPT-Sw3 âœ… âœ… âœ… GPTBigCode âœ… âŒ âŒ GPTSAN-japanese âœ… âŒ âŒ Granite âœ… âŒ âŒ GraniteMoeMoe âœ… âŒ âŒ Graphormer âœ… âŒ âŒ Grounding'),\n",
       " Document(metadata={'source': 'https://huggingface.co/docs/transformers/index', 'title': 'ğŸ¤— Transformers', 'description': 'Weâ€™re on a journey to advance and democratize artificial intelligence through open source and open science.', 'language': 'No language found.'}, page_content='GLM âœ… âŒ âŒ GLPN âœ… âŒ âŒ GPT Neo âœ… âŒ âœ… GPT NeoX âœ… âŒ âŒ GPT NeoX Japanese âœ… âŒ âŒ GPT-J âœ… âœ… âœ… GPT-Sw3 âœ… âœ… âœ… GPTBigCode âœ… âŒ âŒ GPTSAN-japanese âœ… âŒ âŒ Granite âœ… âŒ âŒ GraniteMoeMoe âœ… âŒ âŒ Graphormer âœ… âŒ âŒ Grounding DINO âœ… âŒ âŒ GroupViT âœ… âœ… âŒ HerBERT âœ… âœ… âœ… Hiera âœ… âŒ âŒ Hubert âœ… âœ… âŒ I-BERT âœ… âŒ âŒ I-JEPA âœ… âŒ âŒ IDEFICS âœ… âœ… âŒ Idefics2 âœ… âŒ âŒ Idefics3 âœ… âŒ âŒ Idefics3VisionTransformer âŒ âŒ âŒ ImageGPT âœ… âŒ âŒ Informer âœ… âŒ âŒ InstructBLIP âœ… âŒ âŒ InstructBlipVideo âœ… âŒ âŒ Jamba âœ… âŒ âŒ JetMoe âœ… âŒ âŒ Jukebox âœ… âŒ âŒ KOSMOS-2 âœ… âŒ âŒ LayoutLM âœ… âœ… âŒ LayoutLMv2 âœ… âŒ âŒ LayoutLMv3 âœ… âœ… âŒ LayoutXLM âœ… âŒ âŒ LED âœ… âœ… âŒ LeViT âœ… âŒ âŒ LiLT âœ… âŒ âŒ LLaMA âœ… âŒ âœ… Llama2 âœ… âŒ âœ… Llama3 âœ… âŒ âœ… LLaVa âœ… âŒ âŒ LLaVA-NeXT âœ… âŒ âŒ LLaVa-NeXT-Video âœ… âŒ âŒ LLaVA-Onevision âœ… âŒ âŒ Longformer âœ… âœ… âŒ LongT5 âœ… âŒ âœ… LUKE âœ… âŒ âŒ LXMERT âœ… âœ… âŒ M-CTC-T âœ… âŒ âŒ M2M100 âœ… âŒ âŒ MADLAD-400 âœ… âœ… âœ… Mamba âœ… âŒ âŒ mamba2 âœ… âŒ âŒ Marian âœ… âœ… âœ… MarkupLM âœ… âŒ âŒ Mask2Former âœ… âŒ âŒ MaskFormer âœ… âŒ âŒ MatCha âœ… âŒ âŒ mBART âœ… âœ… âœ… mBART-50 âœ… âœ… âœ… MEGA âœ… âŒ âŒ Megatron-BERT âœ… âŒ âŒ Megatron-GPT2 âœ… âœ… âœ… MGP-STR âœ… âŒ âŒ Mimi'),\n",
       " Document(metadata={'source': 'https://huggingface.co/docs/transformers/index', 'title': 'ğŸ¤— Transformers', 'description': 'Weâ€™re on a journey to advance and democratize artificial intelligence through open source and open science.', 'language': 'No language found.'}, page_content='âœ… Mamba âœ… âŒ âŒ mamba2 âœ… âŒ âŒ Marian âœ… âœ… âœ… MarkupLM âœ… âŒ âŒ Mask2Former âœ… âŒ âŒ MaskFormer âœ… âŒ âŒ MatCha âœ… âŒ âŒ mBART âœ… âœ… âœ… mBART-50 âœ… âœ… âœ… MEGA âœ… âŒ âŒ Megatron-BERT âœ… âŒ âŒ Megatron-GPT2 âœ… âœ… âœ… MGP-STR âœ… âŒ âŒ Mimi âœ… âŒ âŒ Mistral âœ… âœ… âœ… Mixtral âœ… âŒ âŒ Mllama âœ… âŒ âŒ mLUKE âœ… âŒ âŒ MMS âœ… âœ… âœ… MobileBERT âœ… âœ… âŒ MobileNetV1 âœ… âŒ âŒ MobileNetV2 âœ… âŒ âŒ MobileViT âœ… âœ… âŒ MobileViTV2 âœ… âŒ âŒ ModernBERT âœ… âŒ âŒ Moonshine âœ… âŒ âŒ Moshi âœ… âŒ âŒ MPNet âœ… âœ… âŒ MPT âœ… âŒ âŒ MRA âœ… âŒ âŒ MT5 âœ… âœ… âœ… MusicGen âœ… âŒ âŒ MusicGen Melody âœ… âŒ âŒ MVP âœ… âŒ âŒ NAT âœ… âŒ âŒ Nemotron âœ… âŒ âŒ Nezha âœ… âŒ âŒ NLLB âœ… âŒ âŒ NLLB-MOE âœ… âŒ âŒ Nougat âœ… âœ… âœ… NystrÃ¶mformer âœ… âŒ âŒ OLMo âœ… âŒ âŒ OLMo2 âœ… âŒ âŒ OLMoE âœ… âŒ âŒ OmDet-Turbo âœ… âŒ âŒ OneFormer âœ… âŒ âŒ OpenAI GPT âœ… âœ… âŒ OpenAI GPT-2 âœ… âœ… âœ… OpenLlama âœ… âŒ âŒ OPT âœ… âœ… âœ… OWL-ViT âœ… âŒ âŒ OWLv2 âœ… âŒ âŒ PaliGemma âœ… âŒ âŒ PatchTSMixer âœ… âŒ âŒ PatchTST âœ… âŒ âŒ Pegasus âœ… âœ… âœ… PEGASUS-X âœ… âŒ âŒ Perceiver âœ… âŒ âŒ Persimmon âœ… âŒ âŒ Phi âœ… âŒ âŒ Phi3 âœ… âŒ âŒ Phimoe âœ… âŒ âŒ PhoBERT âœ… âœ… âœ… Pix2Struct âœ… âŒ âŒ Pixtral âœ… âŒ âŒ PLBart âœ… âŒ âŒ PoolFormer âœ… âŒ âŒ Pop2Piano âœ… âŒ âŒ ProphetNet âœ… âŒ âŒ'),\n",
       " Document(metadata={'source': 'https://huggingface.co/docs/transformers/index', 'title': 'ğŸ¤— Transformers', 'description': 'Weâ€™re on a journey to advance and democratize artificial intelligence through open source and open science.', 'language': 'No language found.'}, page_content='âœ… âœ… âœ… PEGASUS-X âœ… âŒ âŒ Perceiver âœ… âŒ âŒ Persimmon âœ… âŒ âŒ Phi âœ… âŒ âŒ Phi3 âœ… âŒ âŒ Phimoe âœ… âŒ âŒ PhoBERT âœ… âœ… âœ… Pix2Struct âœ… âŒ âŒ Pixtral âœ… âŒ âŒ PLBart âœ… âŒ âŒ PoolFormer âœ… âŒ âŒ Pop2Piano âœ… âŒ âŒ ProphetNet âœ… âŒ âŒ PVT âœ… âŒ âŒ PVTv2 âœ… âŒ âŒ QDQBert âœ… âŒ âŒ Qwen2 âœ… âŒ âŒ Qwen2Audio âœ… âŒ âŒ Qwen2MoE âœ… âŒ âŒ Qwen2VL âœ… âŒ âŒ RAG âœ… âœ… âŒ REALM âœ… âŒ âŒ RecurrentGemma âœ… âŒ âŒ Reformer âœ… âŒ âŒ RegNet âœ… âœ… âœ… RemBERT âœ… âœ… âŒ ResNet âœ… âœ… âœ… RetriBERT âœ… âŒ âŒ RoBERTa âœ… âœ… âœ… RoBERTa-PreLayerNorm âœ… âœ… âœ… RoCBert âœ… âŒ âŒ RoFormer âœ… âœ… âœ… RT-DETR âœ… âŒ âŒ RT-DETR-ResNet âœ… âŒ âŒ RWKV âœ… âŒ âŒ SAM âœ… âœ… âŒ SeamlessM4T âœ… âŒ âŒ SeamlessM4Tv2 âœ… âŒ âŒ SegFormer âœ… âœ… âŒ SegGPT âœ… âŒ âŒ SEW âœ… âŒ âŒ SEW-D âœ… âŒ âŒ SigLIP âœ… âŒ âŒ Speech Encoder decoder âœ… âŒ âœ… Speech2Text âœ… âœ… âŒ SpeechT5 âœ… âŒ âŒ Splinter âœ… âŒ âŒ SqueezeBERT âœ… âŒ âŒ StableLm âœ… âŒ âŒ Starcoder2 âœ… âŒ âŒ SuperPoint âœ… âŒ âŒ SwiftFormer âœ… âœ… âŒ Swin Transformer âœ… âœ… âŒ Swin Transformer V2 âœ… âŒ âŒ Swin2SR âœ… âŒ âŒ SwitchTransformers âœ… âŒ âŒ T5 âœ… âœ… âœ… T5v1.1 âœ… âœ… âœ… Table Transformer âœ… âŒ âŒ TAPAS âœ… âœ… âŒ TAPEX âœ… âœ… âœ… TextNet âœ… âŒ âŒ Time Series Transformer âœ… âŒ âŒ'),\n",
       " Document(metadata={'source': 'https://huggingface.co/docs/transformers/index', 'title': 'ğŸ¤— Transformers', 'description': 'Weâ€™re on a journey to advance and democratize artificial intelligence through open source and open science.', 'language': 'No language found.'}, page_content='Transformer âœ… âœ… âŒ Swin Transformer V2 âœ… âŒ âŒ Swin2SR âœ… âŒ âŒ SwitchTransformers âœ… âŒ âŒ T5 âœ… âœ… âœ… T5v1.1 âœ… âœ… âœ… Table Transformer âœ… âŒ âŒ TAPAS âœ… âœ… âŒ TAPEX âœ… âœ… âœ… TextNet âœ… âŒ âŒ Time Series Transformer âœ… âŒ âŒ TimeSformer âœ… âŒ âŒ TimmWrapperModel âœ… âŒ âŒ Trajectory Transformer âœ… âŒ âŒ Transformer-XL âœ… âœ… âŒ TrOCR âœ… âŒ âŒ TVLT âœ… âŒ âŒ TVP âœ… âŒ âŒ UDOP âœ… âŒ âŒ UL2 âœ… âœ… âœ… UMT5 âœ… âŒ âŒ UniSpeech âœ… âŒ âŒ UniSpeechSat âœ… âŒ âŒ UnivNet âœ… âŒ âŒ UPerNet âœ… âŒ âŒ VAN âœ… âŒ âŒ VideoLlava âœ… âŒ âŒ VideoMAE âœ… âŒ âŒ ViLT âœ… âŒ âŒ VipLlava âœ… âŒ âŒ Vision Encoder decoder âœ… âœ… âœ… VisionTextDualEncoder âœ… âœ… âœ… VisualBERT âœ… âŒ âŒ ViT âœ… âœ… âœ… ViT Hybrid âœ… âŒ âŒ VitDet âœ… âŒ âŒ ViTMAE âœ… âœ… âŒ ViTMatte âœ… âŒ âŒ ViTMSN âœ… âŒ âŒ VitPose âœ… âŒ âŒ VitPoseBackbone âœ… âŒ âŒ VITS âœ… âŒ âŒ ViViT âœ… âŒ âŒ Wav2Vec2 âœ… âœ… âœ… Wav2Vec2-BERT âœ… âŒ âŒ Wav2Vec2-Conformer âœ… âŒ âŒ Wav2Vec2Phoneme âœ… âœ… âœ… WavLM âœ… âŒ âŒ Whisper âœ… âœ… âœ… X-CLIP âœ… âŒ âŒ X-MOD âœ… âŒ âŒ XGLM âœ… âœ… âœ… XLM âœ… âœ… âŒ XLM-ProphetNet âœ… âŒ âŒ XLM-RoBERTa âœ… âœ… âœ… XLM-RoBERTa-XL âœ… âŒ âŒ XLM-V âœ… âœ… âœ… XLNet âœ… âœ… âŒ XLS-R âœ… âœ… âœ… XLSR-Wav2Vec2 âœ… âœ… âœ… YOLOS âœ… âŒ âŒ YOSO âœ… âŒ âŒ Zamba âœ…'),\n",
       " Document(metadata={'source': 'https://huggingface.co/docs/transformers/index', 'title': 'ğŸ¤— Transformers', 'description': 'Weâ€™re on a journey to advance and democratize artificial intelligence through open source and open science.', 'language': 'No language found.'}, page_content='âœ… âœ… âœ… X-CLIP âœ… âŒ âŒ X-MOD âœ… âŒ âŒ XGLM âœ… âœ… âœ… XLM âœ… âœ… âŒ XLM-ProphetNet âœ… âŒ âŒ XLM-RoBERTa âœ… âœ… âœ… XLM-RoBERTa-XL âœ… âŒ âŒ XLM-V âœ… âœ… âœ… XLNet âœ… âœ… âŒ XLS-R âœ… âœ… âœ… XLSR-Wav2Vec2 âœ… âœ… âœ… YOLOS âœ… âŒ âŒ YOSO âœ… âŒ âŒ Zamba âœ… âŒ âŒ ZoeDepth âœ… âŒ âŒ < > Update on GitHub'),\n",
       " Document(metadata={'source': 'https://huggingface.co/docs/transformers/index', 'title': 'ğŸ¤— Transformers', 'description': 'Weâ€™re on a journey to advance and democratize artificial intelligence through open source and open science.', 'language': 'No language found.'}, page_content='Quick tourâ†’\\n\\n\\nğŸ¤— Transformers\\nIf you are looking for custom support from the Hugging Face team\\nContents\\nSupported models and frameworks')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=200)\n",
    "splitted_docs = splitter.split_documents(docs)\n",
    "splitted_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "embedding = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.faiss.FAISS at 0x19537eb7be0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "db = FAISS.from_documents(splitted_docs,embedding)\n",
    "db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query From vectorDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ğŸ¤— Transformers State-of-the-art Machine Learning for PyTorch, TensorFlow, and JAX. ğŸ¤— Transformers provides APIs and tools to easily download and train state-of-the-art pretrained models. Using pretrained models can reduce your compute costs, carbon footprint, and save you the time and resources required to train a model from scratch. These models support common tasks in different modalities, such as: ğŸ“ Natural Language Processing: text classification, named entity recognition, question answering, language modeling, code generation, summarization, translation, multiple choice, and text generation.\\nğŸ–¼ï¸ Computer Vision: image classification, object detection, and segmentation.\\nğŸ—£ï¸ Audio: automatic speech recognition and audio classification.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Which common tasks are supportted by Transformer models in different modalities?\"\n",
    "result = db.similarity_search(query)\n",
    "result[0].page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load LLM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.Completions object at 0x00000195A49221A0> async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x00000195A4887940> root_client=<openai.OpenAI object at 0x00000195A4922AA0> root_async_client=<openai.AsyncOpenAI object at 0x00000195A49208B0> model_name='gpt-4o' model_kwargs={} openai_api_key=SecretStr('**********')\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieval Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  context: RunnableLambda(format_docs)\n",
       "}), kwargs={}, config={'run_name': 'format_inputs'}, config_factories=[])\n",
       "| ChatPromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template='\\nAnswer the following question based only on the provided context:\\n<context>\\n{context}\\n'), additional_kwargs={})])\n",
       "| ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x00000195A49221A0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x00000195A4887940>, root_client=<openai.OpenAI object at 0x00000195A4922AA0>, root_async_client=<openai.AsyncOpenAI object at 0x00000195A49208B0>, model_name='gpt-4o', model_kwargs={}, openai_api_key=SecretStr('**********'))\n",
       "| StrOutputParser(), kwargs={}, config={'run_name': 'stuff_documents_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "\"\"\"\n",
    "Answer the following question based only on the provided context:\n",
    "<context>\n",
    "{context}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "document_chain = create_stuff_documents_chain(llm,prompt)\n",
    "document_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Transformer models are versatile and support a range of tasks across different modalities. In text or language processing, they support tasks such as translation, text generation, sentiment analysis, and summarization. For vision tasks, they are used in object detection, image classification, and image segmentation. In speech processing, they facilitate tasks like speech recognition and text-to-speech conversion. These models excel in handling and generating data across these modalities due to their ability to capture long-range dependencies and contextual information.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "document_chain.invoke({\n",
    "    \"input\":\"Which common tasks are supportted by Transformer models in different modalities?\",\n",
    "    \"context\": [Document(page_content=\"Which common tasks are supportted by Transformer models in different modalities?\")]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### So far the input we are passing directly to LLM model but at first we want it to go through our vectordb. By this way we will first search related information from vector db and that information along with input will be passed to LLM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  context: RunnableBinding(bound=RunnableLambda(lambda x: x['input'])\n",
       "           | VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000019537EB7BE0>, search_kwargs={}), kwargs={}, config={'run_name': 'retrieve_documents'}, config_factories=[])\n",
       "})\n",
       "| RunnableAssign(mapper={\n",
       "    answer: RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "              context: RunnableLambda(format_docs)\n",
       "            }), kwargs={}, config={'run_name': 'format_inputs'}, config_factories=[])\n",
       "            | ChatPromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template='\\nAnswer the following question based only on the provided context:\\n<context>\\n{context}\\n'), additional_kwargs={})])\n",
       "            | ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x00000195A49221A0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x00000195A4887940>, root_client=<openai.OpenAI object at 0x00000195A4922AA0>, root_async_client=<openai.AsyncOpenAI object at 0x00000195A49208B0>, model_name='gpt-4o', model_kwargs={}, openai_api_key=SecretStr('**********'))\n",
       "            | StrOutputParser(), kwargs={}, config={'run_name': 'stuff_documents_chain'}, config_factories=[])\n",
       "  }), kwargs={}, config={'run_name': 'retrieval_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Retriver :  input =>   retriever => vectordb\n",
    "from langchain.chains import create_retrieval_chain\n",
    "retriever = db.as_retriever()\n",
    "retrieval_chain = create_retrieval_chain(retriever,document_chain)\n",
    "retrieval_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'Does transformer supports PyTorch, TensorFlow, and JAX',\n",
       " 'context': [Document(id='1889cc00-4565-4e84-8665-f61550c3b3a5', metadata={'source': 'https://huggingface.co/docs/transformers/index', 'title': 'ğŸ¤— Transformers', 'description': 'Weâ€™re on a journey to advance and democratize artificial intelligence through open source and open science.', 'language': 'No language found.'}, page_content='ğŸ¤— Transformers State-of-the-art Machine Learning for PyTorch, TensorFlow, and JAX. ğŸ¤— Transformers provides APIs and tools to easily download and train state-of-the-art pretrained models. Using pretrained models can reduce your compute costs, carbon footprint, and save you the time and resources required to train a model from scratch. These models support common tasks in different modalities, such as: ğŸ“ Natural Language Processing: text classification, named entity recognition, question answering, language modeling, code generation, summarization, translation, multiple choice, and text generation.\\nğŸ–¼ï¸ Computer Vision: image classification, object detection, and segmentation.\\nğŸ—£ï¸ Audio: automatic speech recognition and audio classification.'),\n",
       "  Document(id='feda9fc2-7906-4e09-b0cb-0e0475bfa1de', metadata={'source': 'https://huggingface.co/docs/transformers/index', 'title': 'ğŸ¤— Transformers', 'description': 'Weâ€™re on a journey to advance and democratize artificial intelligence through open source and open science.', 'language': 'No language found.'}, page_content='Flax), PyTorch, and/or TensorFlow. Model PyTorch support TensorFlow support Flax Support ALBERT âœ… âœ… âœ… ALIGN âœ… âŒ âŒ AltCLIP âœ… âŒ âŒ Aria âœ… âŒ âŒ AriaText âœ… âŒ âŒ Audio Spectrogram Transformer âœ… âŒ âŒ Autoformer âœ… âŒ âŒ Bamba âœ… âŒ âŒ Bark âœ… âŒ âŒ BART âœ… âœ… âœ… BARThez âœ… âœ… âœ… BARTpho âœ… âœ… âœ… BEiT âœ… âŒ âœ… BERT âœ… âœ… âœ… Bert Generation âœ… âŒ âŒ BertJapanese âœ… âœ… âœ… BERTweet âœ… âœ… âœ… BigBird âœ… âŒ âœ… BigBird-Pegasus âœ… âŒ âŒ BioGpt âœ… âŒ âŒ BiT âœ… âŒ âŒ Blenderbot âœ… âœ… âœ… BlenderbotSmall âœ… âœ… âœ… BLIP âœ… âœ… âŒ BLIP-2 âœ… âŒ âŒ BLOOM âœ… âŒ âœ… BORT âœ… âœ… âœ… BridgeTower âœ… âŒ âŒ BROS âœ… âŒ âŒ ByT5 âœ… âœ… âœ… CamemBERT âœ… âœ… âŒ CANINE âœ… âŒ âŒ Chameleon âœ… âŒ âŒ Chinese-CLIP âœ… âŒ âŒ CLAP âœ… âŒ âŒ CLIP âœ… âœ… âœ… CLIPSeg âœ… âŒ âŒ CLVP âœ… âŒ âŒ CodeGen âœ… âŒ âŒ CodeLlama âœ… âŒ âœ… Cohere âœ… âŒ âŒ Cohere2 âœ… âŒ âŒ ColPali âœ… âŒ âŒ Conditional DETR âœ… âŒ âŒ ConvBERT âœ… âœ… âŒ ConvNeXT âœ… âœ… âŒ ConvNeXTV2 âœ… âœ… âŒ CPM âœ… âœ… âœ… CPM-Ant âœ… âŒ âŒ CTRL âœ… âœ… âŒ CvT âœ… âœ… âŒ DAC âœ… âŒ âŒ Data2VecAudio âœ… âŒ âŒ Data2VecText âœ… âŒ âŒ Data2VecVision âœ… âœ… âŒ DBRX âœ… âŒ âŒ DeBERTa âœ… âœ… âŒ DeBERTa-v2 âœ… âœ… âŒ Decision Transformer âœ… âŒ âŒ Deformable DETR âœ… âŒ âŒ DeiT âœ… âœ…'),\n",
       "  Document(id='94b08dbc-dddf-4efe-b6d6-fb54add8535b', metadata={'source': 'https://huggingface.co/docs/transformers/index', 'title': 'ğŸ¤— Transformers', 'description': 'Weâ€™re on a journey to advance and democratize artificial intelligence through open source and open science.', 'language': 'No language found.'}, page_content='ğŸ™ Multimodal: table question answering, optical character recognition, information extraction from scanned documents, video classification, and visual question answering. ğŸ¤— Transformers support framework interoperability between PyTorch, TensorFlow, and JAX. This provides the flexibility to use a different framework at each stage of a modelâ€™s life; train a model in three lines of code in one framework, and load it for inference in another. Models can also be exported to a format like ONNX and TorchScript for deployment in production environments. Join the growing community on the Hub, forum, or Discord today!  If you are looking for custom support from the Hugging Face team   Contents The documentation is organized into five sections: GET STARTED provides a quick tour of the library and installation instructions to get up and running. TUTORIALS are a great place to start if youâ€™re a beginner. This section will help you gain the basic skills you need to start using the library. HOW-TO'),\n",
       "  Document(id='7c0cd7c7-61ad-4f0c-96ca-ca00efb44e90', metadata={'source': 'https://huggingface.co/docs/transformers/index', 'title': 'ğŸ¤— Transformers', 'description': 'Weâ€™re on a journey to advance and democratize artificial intelligence through open source and open science.', 'language': 'No language found.'}, page_content='Quick tourâ†’\\n\\n\\nğŸ¤— Transformers\\nIf you are looking for custom support from the Hugging Face team\\nContents\\nSupported models and frameworks')],\n",
       " 'answer': 'Which models support all three frameworks: PyTorch, TensorFlow, and Flax?\\n\\n- ALBERT\\n- BART\\n- BARThez\\n- BARTpho\\n- BERT\\n- BertJapanese\\n- BERTweet\\n- Blenderbot\\n- BlenderbotSmall\\n- CamemBERT\\n- CPM'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Get the response from LLM\n",
    "response = retrieval_chain.invoke({\"input\":\"Does transformer supports PyTorch, TensorFlow, and JAX\"})\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Which models support all three frameworks: PyTorch, TensorFlow, and Flax?\\n\\n- ALBERT\\n- BART\\n- BARThez\\n- BARTpho\\n- BERT\\n- BertJapanese\\n- BERTweet\\n- Blenderbot\\n- BlenderbotSmall\\n- CamemBERT\\n- CPM'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='1889cc00-4565-4e84-8665-f61550c3b3a5', metadata={'source': 'https://huggingface.co/docs/transformers/index', 'title': 'ğŸ¤— Transformers', 'description': 'Weâ€™re on a journey to advance and democratize artificial intelligence through open source and open science.', 'language': 'No language found.'}, page_content='ğŸ¤— Transformers State-of-the-art Machine Learning for PyTorch, TensorFlow, and JAX. ğŸ¤— Transformers provides APIs and tools to easily download and train state-of-the-art pretrained models. Using pretrained models can reduce your compute costs, carbon footprint, and save you the time and resources required to train a model from scratch. These models support common tasks in different modalities, such as: ğŸ“ Natural Language Processing: text classification, named entity recognition, question answering, language modeling, code generation, summarization, translation, multiple choice, and text generation.\\nğŸ–¼ï¸ Computer Vision: image classification, object detection, and segmentation.\\nğŸ—£ï¸ Audio: automatic speech recognition and audio classification.'),\n",
       " Document(id='feda9fc2-7906-4e09-b0cb-0e0475bfa1de', metadata={'source': 'https://huggingface.co/docs/transformers/index', 'title': 'ğŸ¤— Transformers', 'description': 'Weâ€™re on a journey to advance and democratize artificial intelligence through open source and open science.', 'language': 'No language found.'}, page_content='Flax), PyTorch, and/or TensorFlow. Model PyTorch support TensorFlow support Flax Support ALBERT âœ… âœ… âœ… ALIGN âœ… âŒ âŒ AltCLIP âœ… âŒ âŒ Aria âœ… âŒ âŒ AriaText âœ… âŒ âŒ Audio Spectrogram Transformer âœ… âŒ âŒ Autoformer âœ… âŒ âŒ Bamba âœ… âŒ âŒ Bark âœ… âŒ âŒ BART âœ… âœ… âœ… BARThez âœ… âœ… âœ… BARTpho âœ… âœ… âœ… BEiT âœ… âŒ âœ… BERT âœ… âœ… âœ… Bert Generation âœ… âŒ âŒ BertJapanese âœ… âœ… âœ… BERTweet âœ… âœ… âœ… BigBird âœ… âŒ âœ… BigBird-Pegasus âœ… âŒ âŒ BioGpt âœ… âŒ âŒ BiT âœ… âŒ âŒ Blenderbot âœ… âœ… âœ… BlenderbotSmall âœ… âœ… âœ… BLIP âœ… âœ… âŒ BLIP-2 âœ… âŒ âŒ BLOOM âœ… âŒ âœ… BORT âœ… âœ… âœ… BridgeTower âœ… âŒ âŒ BROS âœ… âŒ âŒ ByT5 âœ… âœ… âœ… CamemBERT âœ… âœ… âŒ CANINE âœ… âŒ âŒ Chameleon âœ… âŒ âŒ Chinese-CLIP âœ… âŒ âŒ CLAP âœ… âŒ âŒ CLIP âœ… âœ… âœ… CLIPSeg âœ… âŒ âŒ CLVP âœ… âŒ âŒ CodeGen âœ… âŒ âŒ CodeLlama âœ… âŒ âœ… Cohere âœ… âŒ âŒ Cohere2 âœ… âŒ âŒ ColPali âœ… âŒ âŒ Conditional DETR âœ… âŒ âŒ ConvBERT âœ… âœ… âŒ ConvNeXT âœ… âœ… âŒ ConvNeXTV2 âœ… âœ… âŒ CPM âœ… âœ… âœ… CPM-Ant âœ… âŒ âŒ CTRL âœ… âœ… âŒ CvT âœ… âœ… âŒ DAC âœ… âŒ âŒ Data2VecAudio âœ… âŒ âŒ Data2VecText âœ… âŒ âŒ Data2VecVision âœ… âœ… âŒ DBRX âœ… âŒ âŒ DeBERTa âœ… âœ… âŒ DeBERTa-v2 âœ… âœ… âŒ Decision Transformer âœ… âŒ âŒ Deformable DETR âœ… âŒ âŒ DeiT âœ… âœ…'),\n",
       " Document(id='94b08dbc-dddf-4efe-b6d6-fb54add8535b', metadata={'source': 'https://huggingface.co/docs/transformers/index', 'title': 'ğŸ¤— Transformers', 'description': 'Weâ€™re on a journey to advance and democratize artificial intelligence through open source and open science.', 'language': 'No language found.'}, page_content='ğŸ™ Multimodal: table question answering, optical character recognition, information extraction from scanned documents, video classification, and visual question answering. ğŸ¤— Transformers support framework interoperability between PyTorch, TensorFlow, and JAX. This provides the flexibility to use a different framework at each stage of a modelâ€™s life; train a model in three lines of code in one framework, and load it for inference in another. Models can also be exported to a format like ONNX and TorchScript for deployment in production environments. Join the growing community on the Hub, forum, or Discord today!  If you are looking for custom support from the Hugging Face team   Contents The documentation is organized into five sections: GET STARTED provides a quick tour of the library and installation instructions to get up and running. TUTORIALS are a great place to start if youâ€™re a beginner. This section will help you gain the basic skills you need to start using the library. HOW-TO'),\n",
       " Document(id='7c0cd7c7-61ad-4f0c-96ca-ca00efb44e90', metadata={'source': 'https://huggingface.co/docs/transformers/index', 'title': 'ğŸ¤— Transformers', 'description': 'Weâ€™re on a journey to advance and democratize artificial intelligence through open source and open science.', 'language': 'No language found.'}, page_content='Quick tourâ†’\\n\\n\\nğŸ¤— Transformers\\nIf you are looking for custom support from the Hugging Face team\\nContents\\nSupported models and frameworks')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response[\"context\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv_lang",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
