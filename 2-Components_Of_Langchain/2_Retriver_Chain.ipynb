{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Data Ingestion => docs\n",
    "- Text Splitter => splitted_docs\n",
    "- Embedding =>\n",
    "- Retrieval Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')\n",
    "os.environ['LANGSMITH_API_KEY'] = os.getenv(\"LANGSMITH_API_KEY\")\n",
    "os.environ['LANGSMITH_TRACING'] = \"true\"\n",
    "os.environ['LANGSMITH_PROJECT'] = \"Components_Of_Langchain\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Ingestion\n",
    "- From the website we need to scrap the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://huggingface.co/docs/transformers/index', 'title': 'ü§ó Transformers', 'description': 'We‚Äôre on a journey to advance and democratize artificial intelligence through open source and open science.', 'language': 'No language found.'}, page_content='\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nü§ó Transformers\\n\\n\\n\\n\\n\\n\\n\\n\\nHugging Face\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\t\\t\\tModels\\n\\n\\t\\t\\t\\t\\tDatasets\\n\\n\\t\\t\\t\\t\\tSpaces\\n\\n\\t\\t\\t\\t\\tPosts\\n\\n\\t\\t\\t\\t\\tDocs\\n\\n\\t\\t\\t\\t\\tEnterprise\\n\\nPricing\\n\\t\\t\\t\\n\\n\\n\\n\\n\\n\\nLog In\\n\\t\\t\\t\\t\\nSign Up\\n\\t\\t\\t\\t\\t\\n\\n\\n\\nTransformers documentation\\n\\t\\t\\t\\nü§ó Transformers\\n\\n\\n\\nTransformers\\n\\nüè° View all docsAWS Trainium & InferentiaAccelerateAmazon SageMakerArgillaAutoTrainBitsandbytesChat UICompetitionsDataset viewerDatasetsDiffusersDistilabelEvaluateGoogle CloudGoogle TPUsGradioHubHub Python LibraryHugging Face Generative AI Services (HUGS)Huggingface.jsInference API (serverless)Inference Endpoints (dedicated)LeaderboardsLightevalOptimumPEFTSafetensorsSentence TransformersTRLTasksText Embeddings InferenceText Generation InferenceTokenizersTransformersTransformers.jssmolagentstimm\\n\\nSearch documentation\\n\\n\\nmainv4.48.0v4.47.1v4.46.3v4.45.2v4.44.2v4.43.4v4.42.4v4.41.2v4.40.2v4.39.3v4.38.2v4.37.2v4.36.1v4.35.2v4.34.1v4.33.3v4.32.1v4.31.0v4.30.0v4.29.1v4.28.1v4.27.2v4.26.1v4.25.1v4.24.0v4.23.1v4.22.2v4.21.3v4.20.1v4.19.4v4.18.0v4.17.0v4.16.2v4.15.0v4.14.1v4.13.0v4.12.5v4.11.3v4.10.1v4.9.2v4.8.2v4.7.0v4.6.0v4.5.1v4.4.2v4.3.3v4.2.2v4.1.1v4.0.1v3.5.1v3.4.0v3.3.1v3.2.0v3.1.0v3.0.2v2.11.0v2.10.0v2.9.1v2.8.0v2.7.0v2.6.0v2.5.1v2.4.1v2.3.0v2.2.2v2.1.1v2.0.0v1.2.0v1.1.0v1.0.0doc-builder-html\\nARDEENESFRHIITJAKOPTTETRZH\\n\\n\\n\\n\\n\\n\\n\\n\\nGet started\\n\\n\\nü§ó Transformers\\nQuick tour\\nInstallation\\nAdding a new model to `transformers`\\n\\n\\nTutorials\\n\\n\\nRun inference with pipelines\\nWrite portable code with AutoClass\\nPreprocess data\\nFine-tune a pretrained model\\nTrain with a script\\nSet up distributed training with ü§ó Accelerate\\nLoad and train adapters with ü§ó PEFT\\nShare your model\\nAgents 101\\nAgents, supercharged - Multi-agents, External tools, and more\\nGeneration with LLMs\\nChatting with Transformers\\n\\n\\nTask Guides\\n\\n\\n\\nNatural Language Processing\\n\\n\\nAudio\\n\\n\\nComputer Vision\\n\\n\\nMultimodal\\n\\n\\nGeneration\\n\\n\\nPrompting\\n\\n\\n\\nDeveloper guides\\n\\n\\nUse fast tokenizers from ü§ó Tokenizers\\nRun inference with multilingual models\\nUse model-specific APIs\\nShare a custom model\\nChat templates\\nTrainer\\nRun training on Amazon SageMaker\\nExport to ONNX\\nExport to TFLite\\nExport to TorchScript\\nBenchmarks\\nNotebooks with examples\\nCommunity resources\\nTroubleshoot\\nInteroperability with GGUF files\\nInteroperability with TikToken files\\nModularity in `transformers`\\nModel Hacking (overwriting a class to your usage)\\n\\n\\nQuantization Methods\\n\\n\\nGetting started\\nbitsandbytes\\nGPTQ\\nAWQ\\nAQLM\\nVPTQ\\nQuanto\\nEETQ\\nHIGGS\\nHQQ\\nFBGEMM_FP8\\nOptimum\\nTorchAO\\nBitNet\\ncompressed-tensors\\nContribute new quantization method\\n\\n\\nPerformance and scalability\\n\\n\\nOverview\\nLLM inference optimization\\n\\nEfficient training techniques\\n\\n\\nMethods and tools for efficient training on a single GPU\\nMultiple GPUs and parallelism\\nFully Sharded Data Parallel\\nDeepSpeed\\nEfficient training on CPU\\nDistributed CPU training\\nTraining on TPU with TensorFlow\\nPyTorch training on Apple silicon\\nCustom hardware for training\\nHyperparameter Search using Trainer API\\n\\n\\nOptimizing inference\\n\\n\\nCPU inference\\nGPU inference\\nMulti-GPU inference\\n\\nInstantiate a big model\\nDebugging\\nXLA Integration for TensorFlow Models\\nOptimize inference using `torch.compile()`\\n\\n\\nContribute\\n\\n\\nHow to contribute to ü§ó Transformers?\\nHow to add a model to ü§ó Transformers?\\nHow to add a pipeline to ü§ó Transformers?\\nTesting\\nChecks on a Pull Request\\n\\n\\nConceptual guides\\n\\n\\nPhilosophy\\nGlossary\\nWhat ü§ó Transformers can do\\nHow ü§ó Transformers solve tasks\\nThe Transformer model family\\nSummary of the tokenizers\\nAttention mechanisms\\nPadding and truncation\\nBERTology\\nPerplexity of fixed-length models\\nPipelines for webserver inference\\nModel training anatomy\\nGetting the most out of LLMs\\n\\n\\nAPI\\n\\n\\n\\nMain Classes\\n\\n\\nAgents and Tools\\nAuto Classes\\nBackbones\\nCallbacks\\nConfiguration\\nData Collator\\nKeras callbacks\\nLogging\\nModels\\nText Generation\\nONNX\\nOptimization\\nModel outputs\\nPipelines\\nProcessors\\nQuantization\\nTokenizer\\nTrainer\\nDeepSpeed\\nExecuTorch\\nFeature Extractor\\nImage Processor\\n\\n\\nModels\\n\\n\\n\\nText models\\n\\n\\nVision models\\n\\n\\nAudio models\\n\\n\\nVideo models\\n\\n\\nMultimodal models\\n\\n\\nReinforcement learning models\\n\\n\\nTime series models\\n\\n\\nGraph models\\n\\n\\n\\nInternal Helpers\\n\\n\\nCustom Layers and Utilities\\nUtilities for pipelines\\nUtilities for Tokenizers\\nUtilities for Trainer\\nUtilities for Generation\\nUtilities for Image Processors\\nUtilities for Audio processing\\nGeneral Utilities\\nUtilities for Time Series\\n\\n\\n\\n\\n\\nJoin the Hugging Face community\\nand get access to the augmented documentation experience\\n\\t\\t\\n\\nCollaborate on models, datasets and Spaces\\n\\t\\t\\t\\t\\n\\nFaster examples with accelerated inference\\n\\t\\t\\t\\t\\n\\nSwitch between documentation themes\\n\\t\\t\\t\\t\\nSign Up\\nto get started\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n   ü§ó Transformers State-of-the-art Machine Learning for PyTorch, TensorFlow, and JAX. ü§ó Transformers provides APIs and tools to easily download and train state-of-the-art pretrained models. Using pretrained models can reduce your compute costs, carbon footprint, and save you the time and resources required to train a model from scratch. These models support common tasks in different modalities, such as: üìù Natural Language Processing: text classification, named entity recognition, question answering, language modeling, code generation, summarization, translation, multiple choice, and text generation.\\nüñºÔ∏è Computer Vision: image classification, object detection, and segmentation.\\nüó£Ô∏è Audio: automatic speech recognition and audio classification.\\nüêô Multimodal: table question answering, optical character recognition, information extraction from scanned documents, video classification, and visual question answering. ü§ó Transformers support framework interoperability between PyTorch, TensorFlow, and JAX. This provides the flexibility to use a different framework at each stage of a model‚Äôs life; train a model in three lines of code in one framework, and load it for inference in another. Models can also be exported to a format like ONNX and TorchScript for deployment in production environments. Join the growing community on the Hub, forum, or Discord today!  If you are looking for custom support from the Hugging Face team   Contents The documentation is organized into five sections: GET STARTED provides a quick tour of the library and installation instructions to get up and running. TUTORIALS are a great place to start if you‚Äôre a beginner. This section will help you gain the basic skills you need to start using the library. HOW-TO GUIDES show you how to achieve a specific goal, like finetuning a pretrained model for language modeling or how to write and share a custom model. CONCEPTUAL GUIDES offers more discussion and explanation of the underlying concepts and ideas behind models, tasks, and the design philosophy of ü§ó Transformers. API describes all classes and functions: MAIN CLASSES details the most important classes like configuration, model, tokenizer, and pipeline. MODELS details the classes and functions related to each model implemented in the library. INTERNAL HELPERS details utility classes and functions used internally.  Supported models and frameworks The table below represents the current support in the library for each of those models, whether they have a Python\\ntokenizer (called ‚Äúslow‚Äù). A ‚Äúfast‚Äù tokenizer backed by the ü§ó Tokenizers library, whether they have support in Jax (via\\nFlax), PyTorch, and/or TensorFlow. Model PyTorch support TensorFlow support Flax Support ALBERT ‚úÖ ‚úÖ ‚úÖ ALIGN ‚úÖ ‚ùå ‚ùå AltCLIP ‚úÖ ‚ùå ‚ùå Aria ‚úÖ ‚ùå ‚ùå AriaText ‚úÖ ‚ùå ‚ùå Audio Spectrogram Transformer ‚úÖ ‚ùå ‚ùå Autoformer ‚úÖ ‚ùå ‚ùå Bamba ‚úÖ ‚ùå ‚ùå Bark ‚úÖ ‚ùå ‚ùå BART ‚úÖ ‚úÖ ‚úÖ BARThez ‚úÖ ‚úÖ ‚úÖ BARTpho ‚úÖ ‚úÖ ‚úÖ BEiT ‚úÖ ‚ùå ‚úÖ BERT ‚úÖ ‚úÖ ‚úÖ Bert Generation ‚úÖ ‚ùå ‚ùå BertJapanese ‚úÖ ‚úÖ ‚úÖ BERTweet ‚úÖ ‚úÖ ‚úÖ BigBird ‚úÖ ‚ùå ‚úÖ BigBird-Pegasus ‚úÖ ‚ùå ‚ùå BioGpt ‚úÖ ‚ùå ‚ùå BiT ‚úÖ ‚ùå ‚ùå Blenderbot ‚úÖ ‚úÖ ‚úÖ BlenderbotSmall ‚úÖ ‚úÖ ‚úÖ BLIP ‚úÖ ‚úÖ ‚ùå BLIP-2 ‚úÖ ‚ùå ‚ùå BLOOM ‚úÖ ‚ùå ‚úÖ BORT ‚úÖ ‚úÖ ‚úÖ BridgeTower ‚úÖ ‚ùå ‚ùå BROS ‚úÖ ‚ùå ‚ùå ByT5 ‚úÖ ‚úÖ ‚úÖ CamemBERT ‚úÖ ‚úÖ ‚ùå CANINE ‚úÖ ‚ùå ‚ùå Chameleon ‚úÖ ‚ùå ‚ùå Chinese-CLIP ‚úÖ ‚ùå ‚ùå CLAP ‚úÖ ‚ùå ‚ùå CLIP ‚úÖ ‚úÖ ‚úÖ CLIPSeg ‚úÖ ‚ùå ‚ùå CLVP ‚úÖ ‚ùå ‚ùå CodeGen ‚úÖ ‚ùå ‚ùå CodeLlama ‚úÖ ‚ùå ‚úÖ Cohere ‚úÖ ‚ùå ‚ùå Cohere2 ‚úÖ ‚ùå ‚ùå ColPali ‚úÖ ‚ùå ‚ùå Conditional DETR ‚úÖ ‚ùå ‚ùå ConvBERT ‚úÖ ‚úÖ ‚ùå ConvNeXT ‚úÖ ‚úÖ ‚ùå ConvNeXTV2 ‚úÖ ‚úÖ ‚ùå CPM ‚úÖ ‚úÖ ‚úÖ CPM-Ant ‚úÖ ‚ùå ‚ùå CTRL ‚úÖ ‚úÖ ‚ùå CvT ‚úÖ ‚úÖ ‚ùå DAC ‚úÖ ‚ùå ‚ùå Data2VecAudio ‚úÖ ‚ùå ‚ùå Data2VecText ‚úÖ ‚ùå ‚ùå Data2VecVision ‚úÖ ‚úÖ ‚ùå DBRX ‚úÖ ‚ùå ‚ùå DeBERTa ‚úÖ ‚úÖ ‚ùå DeBERTa-v2 ‚úÖ ‚úÖ ‚ùå Decision Transformer ‚úÖ ‚ùå ‚ùå Deformable DETR ‚úÖ ‚ùå ‚ùå DeiT ‚úÖ ‚úÖ ‚ùå DePlot ‚úÖ ‚ùå ‚ùå Depth Anything ‚úÖ ‚ùå ‚ùå DETA ‚úÖ ‚ùå ‚ùå DETR ‚úÖ ‚ùå ‚ùå DialoGPT ‚úÖ ‚úÖ ‚úÖ DiffLlama ‚úÖ ‚ùå ‚ùå DiNAT ‚úÖ ‚ùå ‚ùå DINOv2 ‚úÖ ‚ùå ‚úÖ DINOv2 with Registers ‚úÖ ‚ùå ‚ùå DistilBERT ‚úÖ ‚úÖ ‚úÖ DiT ‚úÖ ‚ùå ‚úÖ DonutSwin ‚úÖ ‚ùå ‚ùå DPR ‚úÖ ‚úÖ ‚ùå DPT ‚úÖ ‚ùå ‚ùå EfficientFormer ‚úÖ ‚úÖ ‚ùå EfficientNet ‚úÖ ‚ùå ‚ùå ELECTRA ‚úÖ ‚úÖ ‚úÖ Emu3 ‚úÖ ‚ùå ‚ùå EnCodec ‚úÖ ‚ùå ‚ùå Encoder decoder ‚úÖ ‚úÖ ‚úÖ ERNIE ‚úÖ ‚ùå ‚ùå ErnieM ‚úÖ ‚ùå ‚ùå ESM ‚úÖ ‚úÖ ‚ùå FairSeq Machine-Translation ‚úÖ ‚ùå ‚ùå Falcon ‚úÖ ‚ùå ‚ùå Falcon3 ‚úÖ ‚ùå ‚úÖ FalconMamba ‚úÖ ‚ùå ‚ùå FastSpeech2Conformer ‚úÖ ‚ùå ‚ùå FLAN-T5 ‚úÖ ‚úÖ ‚úÖ FLAN-UL2 ‚úÖ ‚úÖ ‚úÖ FlauBERT ‚úÖ ‚úÖ ‚ùå FLAVA ‚úÖ ‚ùå ‚ùå FNet ‚úÖ ‚ùå ‚ùå FocalNet ‚úÖ ‚ùå ‚ùå Funnel Transformer ‚úÖ ‚úÖ ‚ùå Fuyu ‚úÖ ‚ùå ‚ùå Gemma ‚úÖ ‚ùå ‚úÖ Gemma2 ‚úÖ ‚ùå ‚ùå GIT ‚úÖ ‚ùå ‚ùå GLM ‚úÖ ‚ùå ‚ùå GLPN ‚úÖ ‚ùå ‚ùå GPT Neo ‚úÖ ‚ùå ‚úÖ GPT NeoX ‚úÖ ‚ùå ‚ùå GPT NeoX Japanese ‚úÖ ‚ùå ‚ùå GPT-J ‚úÖ ‚úÖ ‚úÖ GPT-Sw3 ‚úÖ ‚úÖ ‚úÖ GPTBigCode ‚úÖ ‚ùå ‚ùå GPTSAN-japanese ‚úÖ ‚ùå ‚ùå Granite ‚úÖ ‚ùå ‚ùå GraniteMoeMoe ‚úÖ ‚ùå ‚ùå Graphormer ‚úÖ ‚ùå ‚ùå Grounding DINO ‚úÖ ‚ùå ‚ùå GroupViT ‚úÖ ‚úÖ ‚ùå HerBERT ‚úÖ ‚úÖ ‚úÖ Hiera ‚úÖ ‚ùå ‚ùå Hubert ‚úÖ ‚úÖ ‚ùå I-BERT ‚úÖ ‚ùå ‚ùå I-JEPA ‚úÖ ‚ùå ‚ùå IDEFICS ‚úÖ ‚úÖ ‚ùå Idefics2 ‚úÖ ‚ùå ‚ùå Idefics3 ‚úÖ ‚ùå ‚ùå Idefics3VisionTransformer ‚ùå ‚ùå ‚ùå ImageGPT ‚úÖ ‚ùå ‚ùå Informer ‚úÖ ‚ùå ‚ùå InstructBLIP ‚úÖ ‚ùå ‚ùå InstructBlipVideo ‚úÖ ‚ùå ‚ùå Jamba ‚úÖ ‚ùå ‚ùå JetMoe ‚úÖ ‚ùå ‚ùå Jukebox ‚úÖ ‚ùå ‚ùå KOSMOS-2 ‚úÖ ‚ùå ‚ùå LayoutLM ‚úÖ ‚úÖ ‚ùå LayoutLMv2 ‚úÖ ‚ùå ‚ùå LayoutLMv3 ‚úÖ ‚úÖ ‚ùå LayoutXLM ‚úÖ ‚ùå ‚ùå LED ‚úÖ ‚úÖ ‚ùå LeViT ‚úÖ ‚ùå ‚ùå LiLT ‚úÖ ‚ùå ‚ùå LLaMA ‚úÖ ‚ùå ‚úÖ Llama2 ‚úÖ ‚ùå ‚úÖ Llama3 ‚úÖ ‚ùå ‚úÖ LLaVa ‚úÖ ‚ùå ‚ùå LLaVA-NeXT ‚úÖ ‚ùå ‚ùå LLaVa-NeXT-Video ‚úÖ ‚ùå ‚ùå LLaVA-Onevision ‚úÖ ‚ùå ‚ùå Longformer ‚úÖ ‚úÖ ‚ùå LongT5 ‚úÖ ‚ùå ‚úÖ LUKE ‚úÖ ‚ùå ‚ùå LXMERT ‚úÖ ‚úÖ ‚ùå M-CTC-T ‚úÖ ‚ùå ‚ùå M2M100 ‚úÖ ‚ùå ‚ùå MADLAD-400 ‚úÖ ‚úÖ ‚úÖ Mamba ‚úÖ ‚ùå ‚ùå mamba2 ‚úÖ ‚ùå ‚ùå Marian ‚úÖ ‚úÖ ‚úÖ MarkupLM ‚úÖ ‚ùå ‚ùå Mask2Former ‚úÖ ‚ùå ‚ùå MaskFormer ‚úÖ ‚ùå ‚ùå MatCha ‚úÖ ‚ùå ‚ùå mBART ‚úÖ ‚úÖ ‚úÖ mBART-50 ‚úÖ ‚úÖ ‚úÖ MEGA ‚úÖ ‚ùå ‚ùå Megatron-BERT ‚úÖ ‚ùå ‚ùå Megatron-GPT2 ‚úÖ ‚úÖ ‚úÖ MGP-STR ‚úÖ ‚ùå ‚ùå Mimi ‚úÖ ‚ùå ‚ùå Mistral ‚úÖ ‚úÖ ‚úÖ Mixtral ‚úÖ ‚ùå ‚ùå Mllama ‚úÖ ‚ùå ‚ùå mLUKE ‚úÖ ‚ùå ‚ùå MMS ‚úÖ ‚úÖ ‚úÖ MobileBERT ‚úÖ ‚úÖ ‚ùå MobileNetV1 ‚úÖ ‚ùå ‚ùå MobileNetV2 ‚úÖ ‚ùå ‚ùå MobileViT ‚úÖ ‚úÖ ‚ùå MobileViTV2 ‚úÖ ‚ùå ‚ùå ModernBERT ‚úÖ ‚ùå ‚ùå Moonshine ‚úÖ ‚ùå ‚ùå Moshi ‚úÖ ‚ùå ‚ùå MPNet ‚úÖ ‚úÖ ‚ùå MPT ‚úÖ ‚ùå ‚ùå MRA ‚úÖ ‚ùå ‚ùå MT5 ‚úÖ ‚úÖ ‚úÖ MusicGen ‚úÖ ‚ùå ‚ùå MusicGen Melody ‚úÖ ‚ùå ‚ùå MVP ‚úÖ ‚ùå ‚ùå NAT ‚úÖ ‚ùå ‚ùå Nemotron ‚úÖ ‚ùå ‚ùå Nezha ‚úÖ ‚ùå ‚ùå NLLB ‚úÖ ‚ùå ‚ùå NLLB-MOE ‚úÖ ‚ùå ‚ùå Nougat ‚úÖ ‚úÖ ‚úÖ Nystr√∂mformer ‚úÖ ‚ùå ‚ùå OLMo ‚úÖ ‚ùå ‚ùå OLMo2 ‚úÖ ‚ùå ‚ùå OLMoE ‚úÖ ‚ùå ‚ùå OmDet-Turbo ‚úÖ ‚ùå ‚ùå OneFormer ‚úÖ ‚ùå ‚ùå OpenAI GPT ‚úÖ ‚úÖ ‚ùå OpenAI GPT-2 ‚úÖ ‚úÖ ‚úÖ OpenLlama ‚úÖ ‚ùå ‚ùå OPT ‚úÖ ‚úÖ ‚úÖ OWL-ViT ‚úÖ ‚ùå ‚ùå OWLv2 ‚úÖ ‚ùå ‚ùå PaliGemma ‚úÖ ‚ùå ‚ùå PatchTSMixer ‚úÖ ‚ùå ‚ùå PatchTST ‚úÖ ‚ùå ‚ùå Pegasus ‚úÖ ‚úÖ ‚úÖ PEGASUS-X ‚úÖ ‚ùå ‚ùå Perceiver ‚úÖ ‚ùå ‚ùå Persimmon ‚úÖ ‚ùå ‚ùå Phi ‚úÖ ‚ùå ‚ùå Phi3 ‚úÖ ‚ùå ‚ùå Phimoe ‚úÖ ‚ùå ‚ùå PhoBERT ‚úÖ ‚úÖ ‚úÖ Pix2Struct ‚úÖ ‚ùå ‚ùå Pixtral ‚úÖ ‚ùå ‚ùå PLBart ‚úÖ ‚ùå ‚ùå PoolFormer ‚úÖ ‚ùå ‚ùå Pop2Piano ‚úÖ ‚ùå ‚ùå ProphetNet ‚úÖ ‚ùå ‚ùå PVT ‚úÖ ‚ùå ‚ùå PVTv2 ‚úÖ ‚ùå ‚ùå QDQBert ‚úÖ ‚ùå ‚ùå Qwen2 ‚úÖ ‚ùå ‚ùå Qwen2Audio ‚úÖ ‚ùå ‚ùå Qwen2MoE ‚úÖ ‚ùå ‚ùå Qwen2VL ‚úÖ ‚ùå ‚ùå RAG ‚úÖ ‚úÖ ‚ùå REALM ‚úÖ ‚ùå ‚ùå RecurrentGemma ‚úÖ ‚ùå ‚ùå Reformer ‚úÖ ‚ùå ‚ùå RegNet ‚úÖ ‚úÖ ‚úÖ RemBERT ‚úÖ ‚úÖ ‚ùå ResNet ‚úÖ ‚úÖ ‚úÖ RetriBERT ‚úÖ ‚ùå ‚ùå RoBERTa ‚úÖ ‚úÖ ‚úÖ RoBERTa-PreLayerNorm ‚úÖ ‚úÖ ‚úÖ RoCBert ‚úÖ ‚ùå ‚ùå RoFormer ‚úÖ ‚úÖ ‚úÖ RT-DETR ‚úÖ ‚ùå ‚ùå RT-DETR-ResNet ‚úÖ ‚ùå ‚ùå RWKV ‚úÖ ‚ùå ‚ùå SAM ‚úÖ ‚úÖ ‚ùå SeamlessM4T ‚úÖ ‚ùå ‚ùå SeamlessM4Tv2 ‚úÖ ‚ùå ‚ùå SegFormer ‚úÖ ‚úÖ ‚ùå SegGPT ‚úÖ ‚ùå ‚ùå SEW ‚úÖ ‚ùå ‚ùå SEW-D ‚úÖ ‚ùå ‚ùå SigLIP ‚úÖ ‚ùå ‚ùå Speech Encoder decoder ‚úÖ ‚ùå ‚úÖ Speech2Text ‚úÖ ‚úÖ ‚ùå SpeechT5 ‚úÖ ‚ùå ‚ùå Splinter ‚úÖ ‚ùå ‚ùå SqueezeBERT ‚úÖ ‚ùå ‚ùå StableLm ‚úÖ ‚ùå ‚ùå Starcoder2 ‚úÖ ‚ùå ‚ùå SuperPoint ‚úÖ ‚ùå ‚ùå SwiftFormer ‚úÖ ‚úÖ ‚ùå Swin Transformer ‚úÖ ‚úÖ ‚ùå Swin Transformer V2 ‚úÖ ‚ùå ‚ùå Swin2SR ‚úÖ ‚ùå ‚ùå SwitchTransformers ‚úÖ ‚ùå ‚ùå T5 ‚úÖ ‚úÖ ‚úÖ T5v1.1 ‚úÖ ‚úÖ ‚úÖ Table Transformer ‚úÖ ‚ùå ‚ùå TAPAS ‚úÖ ‚úÖ ‚ùå TAPEX ‚úÖ ‚úÖ ‚úÖ TextNet ‚úÖ ‚ùå ‚ùå Time Series Transformer ‚úÖ ‚ùå ‚ùå TimeSformer ‚úÖ ‚ùå ‚ùå TimmWrapperModel ‚úÖ ‚ùå ‚ùå Trajectory Transformer ‚úÖ ‚ùå ‚ùå Transformer-XL ‚úÖ ‚úÖ ‚ùå TrOCR ‚úÖ ‚ùå ‚ùå TVLT ‚úÖ ‚ùå ‚ùå TVP ‚úÖ ‚ùå ‚ùå UDOP ‚úÖ ‚ùå ‚ùå UL2 ‚úÖ ‚úÖ ‚úÖ UMT5 ‚úÖ ‚ùå ‚ùå UniSpeech ‚úÖ ‚ùå ‚ùå UniSpeechSat ‚úÖ ‚ùå ‚ùå UnivNet ‚úÖ ‚ùå ‚ùå UPerNet ‚úÖ ‚ùå ‚ùå VAN ‚úÖ ‚ùå ‚ùå VideoLlava ‚úÖ ‚ùå ‚ùå VideoMAE ‚úÖ ‚ùå ‚ùå ViLT ‚úÖ ‚ùå ‚ùå VipLlava ‚úÖ ‚ùå ‚ùå Vision Encoder decoder ‚úÖ ‚úÖ ‚úÖ VisionTextDualEncoder ‚úÖ ‚úÖ ‚úÖ VisualBERT ‚úÖ ‚ùå ‚ùå ViT ‚úÖ ‚úÖ ‚úÖ ViT Hybrid ‚úÖ ‚ùå ‚ùå VitDet ‚úÖ ‚ùå ‚ùå ViTMAE ‚úÖ ‚úÖ ‚ùå ViTMatte ‚úÖ ‚ùå ‚ùå ViTMSN ‚úÖ ‚ùå ‚ùå VitPose ‚úÖ ‚ùå ‚ùå VitPoseBackbone ‚úÖ ‚ùå ‚ùå VITS ‚úÖ ‚ùå ‚ùå ViViT ‚úÖ ‚ùå ‚ùå Wav2Vec2 ‚úÖ ‚úÖ ‚úÖ Wav2Vec2-BERT ‚úÖ ‚ùå ‚ùå Wav2Vec2-Conformer ‚úÖ ‚ùå ‚ùå Wav2Vec2Phoneme ‚úÖ ‚úÖ ‚úÖ WavLM ‚úÖ ‚ùå ‚ùå Whisper ‚úÖ ‚úÖ ‚úÖ X-CLIP ‚úÖ ‚ùå ‚ùå X-MOD ‚úÖ ‚ùå ‚ùå XGLM ‚úÖ ‚úÖ ‚úÖ XLM ‚úÖ ‚úÖ ‚ùå XLM-ProphetNet ‚úÖ ‚ùå ‚ùå XLM-RoBERTa ‚úÖ ‚úÖ ‚úÖ XLM-RoBERTa-XL ‚úÖ ‚ùå ‚ùå XLM-V ‚úÖ ‚úÖ ‚úÖ XLNet ‚úÖ ‚úÖ ‚ùå XLS-R ‚úÖ ‚úÖ ‚úÖ XLSR-Wav2Vec2 ‚úÖ ‚úÖ ‚úÖ YOLOS ‚úÖ ‚ùå ‚ùå YOSO ‚úÖ ‚ùå ‚ùå Zamba ‚úÖ ‚ùå ‚ùå ZoeDepth ‚úÖ ‚ùå ‚ùå < > Update on GitHub \\n\\n\\n\\nQuick tour‚Üí\\n\\n\\nü§ó Transformers\\nIf you are looking for custom support from the Hugging Face team\\nContents\\nSupported models and frameworks\\n\\n\\n\\n\\n\\n\\n\\n\\n')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "loader = WebBaseLoader(\"https://huggingface.co/docs/transformers/index\")\n",
    "docs = loader.load()\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://huggingface.co/docs/transformers/index', 'title': 'ü§ó Transformers', 'description': 'We‚Äôre on a journey to advance and democratize artificial intelligence through open source and open science.', 'language': 'No language found.'}, page_content='ü§ó Transformers\\n\\n\\n\\n\\n\\n\\n\\n\\nHugging Face\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\t\\t\\tModels\\n\\n\\t\\t\\t\\t\\tDatasets\\n\\n\\t\\t\\t\\t\\tSpaces\\n\\n\\t\\t\\t\\t\\tPosts\\n\\n\\t\\t\\t\\t\\tDocs\\n\\n\\t\\t\\t\\t\\tEnterprise\\n\\nPricing\\n\\t\\t\\t\\n\\n\\n\\n\\n\\n\\nLog In\\n\\t\\t\\t\\t\\nSign Up\\n\\t\\t\\t\\t\\t\\n\\n\\n\\nTransformers documentation\\n\\t\\t\\t\\nü§ó Transformers\\n\\n\\n\\nTransformers\\n\\nüè° View all docsAWS Trainium & InferentiaAccelerateAmazon SageMakerArgillaAutoTrainBitsandbytesChat UICompetitionsDataset viewerDatasetsDiffusersDistilabelEvaluateGoogle CloudGoogle TPUsGradioHubHub Python LibraryHugging Face Generative AI Services (HUGS)Huggingface.jsInference API (serverless)Inference Endpoints (dedicated)LeaderboardsLightevalOptimumPEFTSafetensorsSentence TransformersTRLTasksText Embeddings InferenceText Generation InferenceTokenizersTransformersTransformers.jssmolagentstimm\\n\\nSearch documentation'),\n",
       " Document(metadata={'source': 'https://huggingface.co/docs/transformers/index', 'title': 'ü§ó Transformers', 'description': 'We‚Äôre on a journey to advance and democratize artificial intelligence through open source and open science.', 'language': 'No language found.'}, page_content='Search documentation\\n\\n\\nmainv4.48.0v4.47.1v4.46.3v4.45.2v4.44.2v4.43.4v4.42.4v4.41.2v4.40.2v4.39.3v4.38.2v4.37.2v4.36.1v4.35.2v4.34.1v4.33.3v4.32.1v4.31.0v4.30.0v4.29.1v4.28.1v4.27.2v4.26.1v4.25.1v4.24.0v4.23.1v4.22.2v4.21.3v4.20.1v4.19.4v4.18.0v4.17.0v4.16.2v4.15.0v4.14.1v4.13.0v4.12.5v4.11.3v4.10.1v4.9.2v4.8.2v4.7.0v4.6.0v4.5.1v4.4.2v4.3.3v4.2.2v4.1.1v4.0.1v3.5.1v3.4.0v3.3.1v3.2.0v3.1.0v3.0.2v2.11.0v2.10.0v2.9.1v2.8.0v2.7.0v2.6.0v2.5.1v2.4.1v2.3.0v2.2.2v2.1.1v2.0.0v1.2.0v1.1.0v1.0.0doc-builder-html\\nARDEENESFRHIITJAKOPTTETRZH\\n\\n\\n\\n\\n\\n\\n\\n\\nGet started\\n\\n\\nü§ó Transformers\\nQuick tour\\nInstallation\\nAdding a new model to `transformers`\\n\\n\\nTutorials\\n\\n\\nRun inference with pipelines\\nWrite portable code with AutoClass\\nPreprocess data\\nFine-tune a pretrained model\\nTrain with a script\\nSet up distributed training with ü§ó Accelerate\\nLoad and train adapters with ü§ó PEFT\\nShare your model\\nAgents 101\\nAgents, supercharged - Multi-agents, External tools, and more\\nGeneration with LLMs\\nChatting with Transformers'),\n",
       " Document(metadata={'source': 'https://huggingface.co/docs/transformers/index', 'title': 'ü§ó Transformers', 'description': 'We‚Äôre on a journey to advance and democratize artificial intelligence through open source and open science.', 'language': 'No language found.'}, page_content='Task Guides\\n\\n\\n\\nNatural Language Processing\\n\\n\\nAudio\\n\\n\\nComputer Vision\\n\\n\\nMultimodal\\n\\n\\nGeneration\\n\\n\\nPrompting\\n\\n\\n\\nDeveloper guides\\n\\n\\nUse fast tokenizers from ü§ó Tokenizers\\nRun inference with multilingual models\\nUse model-specific APIs\\nShare a custom model\\nChat templates\\nTrainer\\nRun training on Amazon SageMaker\\nExport to ONNX\\nExport to TFLite\\nExport to TorchScript\\nBenchmarks\\nNotebooks with examples\\nCommunity resources\\nTroubleshoot\\nInteroperability with GGUF files\\nInteroperability with TikToken files\\nModularity in `transformers`\\nModel Hacking (overwriting a class to your usage)\\n\\n\\nQuantization Methods\\n\\n\\nGetting started\\nbitsandbytes\\nGPTQ\\nAWQ\\nAQLM\\nVPTQ\\nQuanto\\nEETQ\\nHIGGS\\nHQQ\\nFBGEMM_FP8\\nOptimum\\nTorchAO\\nBitNet\\ncompressed-tensors\\nContribute new quantization method\\n\\n\\nPerformance and scalability\\n\\n\\nOverview\\nLLM inference optimization\\n\\nEfficient training techniques'),\n",
       " Document(metadata={'source': 'https://huggingface.co/docs/transformers/index', 'title': 'ü§ó Transformers', 'description': 'We‚Äôre on a journey to advance and democratize artificial intelligence through open source and open science.', 'language': 'No language found.'}, page_content='Performance and scalability\\n\\n\\nOverview\\nLLM inference optimization\\n\\nEfficient training techniques\\n\\n\\nMethods and tools for efficient training on a single GPU\\nMultiple GPUs and parallelism\\nFully Sharded Data Parallel\\nDeepSpeed\\nEfficient training on CPU\\nDistributed CPU training\\nTraining on TPU with TensorFlow\\nPyTorch training on Apple silicon\\nCustom hardware for training\\nHyperparameter Search using Trainer API\\n\\n\\nOptimizing inference\\n\\n\\nCPU inference\\nGPU inference\\nMulti-GPU inference\\n\\nInstantiate a big model\\nDebugging\\nXLA Integration for TensorFlow Models\\nOptimize inference using `torch.compile()`\\n\\n\\nContribute\\n\\n\\nHow to contribute to ü§ó Transformers?\\nHow to add a model to ü§ó Transformers?\\nHow to add a pipeline to ü§ó Transformers?\\nTesting\\nChecks on a Pull Request\\n\\n\\nConceptual guides'),\n",
       " Document(metadata={'source': 'https://huggingface.co/docs/transformers/index', 'title': 'ü§ó Transformers', 'description': 'We‚Äôre on a journey to advance and democratize artificial intelligence through open source and open science.', 'language': 'No language found.'}, page_content='Contribute\\n\\n\\nHow to contribute to ü§ó Transformers?\\nHow to add a model to ü§ó Transformers?\\nHow to add a pipeline to ü§ó Transformers?\\nTesting\\nChecks on a Pull Request\\n\\n\\nConceptual guides\\n\\n\\nPhilosophy\\nGlossary\\nWhat ü§ó Transformers can do\\nHow ü§ó Transformers solve tasks\\nThe Transformer model family\\nSummary of the tokenizers\\nAttention mechanisms\\nPadding and truncation\\nBERTology\\nPerplexity of fixed-length models\\nPipelines for webserver inference\\nModel training anatomy\\nGetting the most out of LLMs\\n\\n\\nAPI\\n\\n\\n\\nMain Classes\\n\\n\\nAgents and Tools\\nAuto Classes\\nBackbones\\nCallbacks\\nConfiguration\\nData Collator\\nKeras callbacks\\nLogging\\nModels\\nText Generation\\nONNX\\nOptimization\\nModel outputs\\nPipelines\\nProcessors\\nQuantization\\nTokenizer\\nTrainer\\nDeepSpeed\\nExecuTorch\\nFeature Extractor\\nImage Processor\\n\\n\\nModels\\n\\n\\n\\nText models\\n\\n\\nVision models\\n\\n\\nAudio models\\n\\n\\nVideo models\\n\\n\\nMultimodal models\\n\\n\\nReinforcement learning models\\n\\n\\nTime series models\\n\\n\\nGraph models\\n\\n\\n\\nInternal Helpers'),\n",
       " Document(metadata={'source': 'https://huggingface.co/docs/transformers/index', 'title': 'ü§ó Transformers', 'description': 'We‚Äôre on a journey to advance and democratize artificial intelligence through open source and open science.', 'language': 'No language found.'}, page_content='Models\\n\\n\\n\\nText models\\n\\n\\nVision models\\n\\n\\nAudio models\\n\\n\\nVideo models\\n\\n\\nMultimodal models\\n\\n\\nReinforcement learning models\\n\\n\\nTime series models\\n\\n\\nGraph models\\n\\n\\n\\nInternal Helpers\\n\\n\\nCustom Layers and Utilities\\nUtilities for pipelines\\nUtilities for Tokenizers\\nUtilities for Trainer\\nUtilities for Generation\\nUtilities for Image Processors\\nUtilities for Audio processing\\nGeneral Utilities\\nUtilities for Time Series\\n\\n\\n\\n\\n\\nJoin the Hugging Face community\\nand get access to the augmented documentation experience\\n\\t\\t\\n\\nCollaborate on models, datasets and Spaces\\n\\t\\t\\t\\t\\n\\nFaster examples with accelerated inference\\n\\t\\t\\t\\t\\n\\nSwitch between documentation themes\\n\\t\\t\\t\\t\\nSign Up\\nto get started'),\n",
       " Document(metadata={'source': 'https://huggingface.co/docs/transformers/index', 'title': 'ü§ó Transformers', 'description': 'We‚Äôre on a journey to advance and democratize artificial intelligence through open source and open science.', 'language': 'No language found.'}, page_content='ü§ó Transformers State-of-the-art Machine Learning for PyTorch, TensorFlow, and JAX. ü§ó Transformers provides APIs and tools to easily download and train state-of-the-art pretrained models. Using pretrained models can reduce your compute costs, carbon footprint, and save you the time and resources required to train a model from scratch. These models support common tasks in different modalities, such as: üìù Natural Language Processing: text classification, named entity recognition, question answering, language modeling, code generation, summarization, translation, multiple choice, and text generation.\\nüñºÔ∏è Computer Vision: image classification, object detection, and segmentation.\\nüó£Ô∏è Audio: automatic speech recognition and audio classification.'),\n",
       " Document(metadata={'source': 'https://huggingface.co/docs/transformers/index', 'title': 'ü§ó Transformers', 'description': 'We‚Äôre on a journey to advance and democratize artificial intelligence through open source and open science.', 'language': 'No language found.'}, page_content='üêô Multimodal: table question answering, optical character recognition, information extraction from scanned documents, video classification, and visual question answering. ü§ó Transformers support framework interoperability between PyTorch, TensorFlow, and JAX. This provides the flexibility to use a different framework at each stage of a model‚Äôs life; train a model in three lines of code in one framework, and load it for inference in another. Models can also be exported to a format like ONNX and TorchScript for deployment in production environments. Join the growing community on the Hub, forum, or Discord today!  If you are looking for custom support from the Hugging Face team   Contents The documentation is organized into five sections: GET STARTED provides a quick tour of the library and installation instructions to get up and running. TUTORIALS are a great place to start if you‚Äôre a beginner. This section will help you gain the basic skills you need to start using the library. HOW-TO'),\n",
       " Document(metadata={'source': 'https://huggingface.co/docs/transformers/index', 'title': 'ü§ó Transformers', 'description': 'We‚Äôre on a journey to advance and democratize artificial intelligence through open source and open science.', 'language': 'No language found.'}, page_content='instructions to get up and running. TUTORIALS are a great place to start if you‚Äôre a beginner. This section will help you gain the basic skills you need to start using the library. HOW-TO GUIDES show you how to achieve a specific goal, like finetuning a pretrained model for language modeling or how to write and share a custom model. CONCEPTUAL GUIDES offers more discussion and explanation of the underlying concepts and ideas behind models, tasks, and the design philosophy of ü§ó Transformers. API describes all classes and functions: MAIN CLASSES details the most important classes like configuration, model, tokenizer, and pipeline. MODELS details the classes and functions related to each model implemented in the library. INTERNAL HELPERS details utility classes and functions used internally.  Supported models and frameworks The table below represents the current support in the library for each of those models, whether they have a Python'),\n",
       " Document(metadata={'source': 'https://huggingface.co/docs/transformers/index', 'title': 'ü§ó Transformers', 'description': 'We‚Äôre on a journey to advance and democratize artificial intelligence through open source and open science.', 'language': 'No language found.'}, page_content='tokenizer (called ‚Äúslow‚Äù). A ‚Äúfast‚Äù tokenizer backed by the ü§ó Tokenizers library, whether they have support in Jax (via'),\n",
       " Document(metadata={'source': 'https://huggingface.co/docs/transformers/index', 'title': 'ü§ó Transformers', 'description': 'We‚Äôre on a journey to advance and democratize artificial intelligence through open source and open science.', 'language': 'No language found.'}, page_content='Flax), PyTorch, and/or TensorFlow. Model PyTorch support TensorFlow support Flax Support ALBERT ‚úÖ ‚úÖ ‚úÖ ALIGN ‚úÖ ‚ùå ‚ùå AltCLIP ‚úÖ ‚ùå ‚ùå Aria ‚úÖ ‚ùå ‚ùå AriaText ‚úÖ ‚ùå ‚ùå Audio Spectrogram Transformer ‚úÖ ‚ùå ‚ùå Autoformer ‚úÖ ‚ùå ‚ùå Bamba ‚úÖ ‚ùå ‚ùå Bark ‚úÖ ‚ùå ‚ùå BART ‚úÖ ‚úÖ ‚úÖ BARThez ‚úÖ ‚úÖ ‚úÖ BARTpho ‚úÖ ‚úÖ ‚úÖ BEiT ‚úÖ ‚ùå ‚úÖ BERT ‚úÖ ‚úÖ ‚úÖ Bert Generation ‚úÖ ‚ùå ‚ùå BertJapanese ‚úÖ ‚úÖ ‚úÖ BERTweet ‚úÖ ‚úÖ ‚úÖ BigBird ‚úÖ ‚ùå ‚úÖ BigBird-Pegasus ‚úÖ ‚ùå ‚ùå BioGpt ‚úÖ ‚ùå ‚ùå BiT ‚úÖ ‚ùå ‚ùå Blenderbot ‚úÖ ‚úÖ ‚úÖ BlenderbotSmall ‚úÖ ‚úÖ ‚úÖ BLIP ‚úÖ ‚úÖ ‚ùå BLIP-2 ‚úÖ ‚ùå ‚ùå BLOOM ‚úÖ ‚ùå ‚úÖ BORT ‚úÖ ‚úÖ ‚úÖ BridgeTower ‚úÖ ‚ùå ‚ùå BROS ‚úÖ ‚ùå ‚ùå ByT5 ‚úÖ ‚úÖ ‚úÖ CamemBERT ‚úÖ ‚úÖ ‚ùå CANINE ‚úÖ ‚ùå ‚ùå Chameleon ‚úÖ ‚ùå ‚ùå Chinese-CLIP ‚úÖ ‚ùå ‚ùå CLAP ‚úÖ ‚ùå ‚ùå CLIP ‚úÖ ‚úÖ ‚úÖ CLIPSeg ‚úÖ ‚ùå ‚ùå CLVP ‚úÖ ‚ùå ‚ùå CodeGen ‚úÖ ‚ùå ‚ùå CodeLlama ‚úÖ ‚ùå ‚úÖ Cohere ‚úÖ ‚ùå ‚ùå Cohere2 ‚úÖ ‚ùå ‚ùå ColPali ‚úÖ ‚ùå ‚ùå Conditional DETR ‚úÖ ‚ùå ‚ùå ConvBERT ‚úÖ ‚úÖ ‚ùå ConvNeXT ‚úÖ ‚úÖ ‚ùå ConvNeXTV2 ‚úÖ ‚úÖ ‚ùå CPM ‚úÖ ‚úÖ ‚úÖ CPM-Ant ‚úÖ ‚ùå ‚ùå CTRL ‚úÖ ‚úÖ ‚ùå CvT ‚úÖ ‚úÖ ‚ùå DAC ‚úÖ ‚ùå ‚ùå Data2VecAudio ‚úÖ ‚ùå ‚ùå Data2VecText ‚úÖ ‚ùå ‚ùå Data2VecVision ‚úÖ ‚úÖ ‚ùå DBRX ‚úÖ ‚ùå ‚ùå DeBERTa ‚úÖ ‚úÖ ‚ùå DeBERTa-v2 ‚úÖ ‚úÖ ‚ùå Decision Transformer ‚úÖ ‚ùå ‚ùå Deformable DETR ‚úÖ ‚ùå ‚ùå DeiT ‚úÖ ‚úÖ'),\n",
       " Document(metadata={'source': 'https://huggingface.co/docs/transformers/index', 'title': 'ü§ó Transformers', 'description': 'We‚Äôre on a journey to advance and democratize artificial intelligence through open source and open science.', 'language': 'No language found.'}, page_content='‚úÖ ‚ùå ‚ùå CTRL ‚úÖ ‚úÖ ‚ùå CvT ‚úÖ ‚úÖ ‚ùå DAC ‚úÖ ‚ùå ‚ùå Data2VecAudio ‚úÖ ‚ùå ‚ùå Data2VecText ‚úÖ ‚ùå ‚ùå Data2VecVision ‚úÖ ‚úÖ ‚ùå DBRX ‚úÖ ‚ùå ‚ùå DeBERTa ‚úÖ ‚úÖ ‚ùå DeBERTa-v2 ‚úÖ ‚úÖ ‚ùå Decision Transformer ‚úÖ ‚ùå ‚ùå Deformable DETR ‚úÖ ‚ùå ‚ùå DeiT ‚úÖ ‚úÖ ‚ùå DePlot ‚úÖ ‚ùå ‚ùå Depth Anything ‚úÖ ‚ùå ‚ùå DETA ‚úÖ ‚ùå ‚ùå DETR ‚úÖ ‚ùå ‚ùå DialoGPT ‚úÖ ‚úÖ ‚úÖ DiffLlama ‚úÖ ‚ùå ‚ùå DiNAT ‚úÖ ‚ùå ‚ùå DINOv2 ‚úÖ ‚ùå ‚úÖ DINOv2 with Registers ‚úÖ ‚ùå ‚ùå DistilBERT ‚úÖ ‚úÖ ‚úÖ DiT ‚úÖ ‚ùå ‚úÖ DonutSwin ‚úÖ ‚ùå ‚ùå DPR ‚úÖ ‚úÖ ‚ùå DPT ‚úÖ ‚ùå ‚ùå EfficientFormer ‚úÖ ‚úÖ ‚ùå EfficientNet ‚úÖ ‚ùå ‚ùå ELECTRA ‚úÖ ‚úÖ ‚úÖ Emu3 ‚úÖ ‚ùå ‚ùå EnCodec ‚úÖ ‚ùå ‚ùå Encoder decoder ‚úÖ ‚úÖ ‚úÖ ERNIE ‚úÖ ‚ùå ‚ùå ErnieM ‚úÖ ‚ùå ‚ùå ESM ‚úÖ ‚úÖ ‚ùå FairSeq Machine-Translation ‚úÖ ‚ùå ‚ùå Falcon ‚úÖ ‚ùå ‚ùå Falcon3 ‚úÖ ‚ùå ‚úÖ FalconMamba ‚úÖ ‚ùå ‚ùå FastSpeech2Conformer ‚úÖ ‚ùå ‚ùå FLAN-T5 ‚úÖ ‚úÖ ‚úÖ FLAN-UL2 ‚úÖ ‚úÖ ‚úÖ FlauBERT ‚úÖ ‚úÖ ‚ùå FLAVA ‚úÖ ‚ùå ‚ùå FNet ‚úÖ ‚ùå ‚ùå FocalNet ‚úÖ ‚ùå ‚ùå Funnel Transformer ‚úÖ ‚úÖ ‚ùå Fuyu ‚úÖ ‚ùå ‚ùå Gemma ‚úÖ ‚ùå ‚úÖ Gemma2 ‚úÖ ‚ùå ‚ùå GIT ‚úÖ ‚ùå ‚ùå GLM ‚úÖ ‚ùå ‚ùå GLPN ‚úÖ ‚ùå ‚ùå GPT Neo ‚úÖ ‚ùå ‚úÖ GPT NeoX ‚úÖ ‚ùå ‚ùå GPT NeoX Japanese ‚úÖ ‚ùå ‚ùå GPT-J ‚úÖ ‚úÖ ‚úÖ GPT-Sw3 ‚úÖ ‚úÖ ‚úÖ GPTBigCode ‚úÖ ‚ùå ‚ùå GPTSAN-japanese ‚úÖ ‚ùå ‚ùå Granite ‚úÖ ‚ùå ‚ùå GraniteMoeMoe ‚úÖ ‚ùå ‚ùå Graphormer ‚úÖ ‚ùå ‚ùå Grounding'),\n",
       " Document(metadata={'source': 'https://huggingface.co/docs/transformers/index', 'title': 'ü§ó Transformers', 'description': 'We‚Äôre on a journey to advance and democratize artificial intelligence through open source and open science.', 'language': 'No language found.'}, page_content='GLM ‚úÖ ‚ùå ‚ùå GLPN ‚úÖ ‚ùå ‚ùå GPT Neo ‚úÖ ‚ùå ‚úÖ GPT NeoX ‚úÖ ‚ùå ‚ùå GPT NeoX Japanese ‚úÖ ‚ùå ‚ùå GPT-J ‚úÖ ‚úÖ ‚úÖ GPT-Sw3 ‚úÖ ‚úÖ ‚úÖ GPTBigCode ‚úÖ ‚ùå ‚ùå GPTSAN-japanese ‚úÖ ‚ùå ‚ùå Granite ‚úÖ ‚ùå ‚ùå GraniteMoeMoe ‚úÖ ‚ùå ‚ùå Graphormer ‚úÖ ‚ùå ‚ùå Grounding DINO ‚úÖ ‚ùå ‚ùå GroupViT ‚úÖ ‚úÖ ‚ùå HerBERT ‚úÖ ‚úÖ ‚úÖ Hiera ‚úÖ ‚ùå ‚ùå Hubert ‚úÖ ‚úÖ ‚ùå I-BERT ‚úÖ ‚ùå ‚ùå I-JEPA ‚úÖ ‚ùå ‚ùå IDEFICS ‚úÖ ‚úÖ ‚ùå Idefics2 ‚úÖ ‚ùå ‚ùå Idefics3 ‚úÖ ‚ùå ‚ùå Idefics3VisionTransformer ‚ùå ‚ùå ‚ùå ImageGPT ‚úÖ ‚ùå ‚ùå Informer ‚úÖ ‚ùå ‚ùå InstructBLIP ‚úÖ ‚ùå ‚ùå InstructBlipVideo ‚úÖ ‚ùå ‚ùå Jamba ‚úÖ ‚ùå ‚ùå JetMoe ‚úÖ ‚ùå ‚ùå Jukebox ‚úÖ ‚ùå ‚ùå KOSMOS-2 ‚úÖ ‚ùå ‚ùå LayoutLM ‚úÖ ‚úÖ ‚ùå LayoutLMv2 ‚úÖ ‚ùå ‚ùå LayoutLMv3 ‚úÖ ‚úÖ ‚ùå LayoutXLM ‚úÖ ‚ùå ‚ùå LED ‚úÖ ‚úÖ ‚ùå LeViT ‚úÖ ‚ùå ‚ùå LiLT ‚úÖ ‚ùå ‚ùå LLaMA ‚úÖ ‚ùå ‚úÖ Llama2 ‚úÖ ‚ùå ‚úÖ Llama3 ‚úÖ ‚ùå ‚úÖ LLaVa ‚úÖ ‚ùå ‚ùå LLaVA-NeXT ‚úÖ ‚ùå ‚ùå LLaVa-NeXT-Video ‚úÖ ‚ùå ‚ùå LLaVA-Onevision ‚úÖ ‚ùå ‚ùå Longformer ‚úÖ ‚úÖ ‚ùå LongT5 ‚úÖ ‚ùå ‚úÖ LUKE ‚úÖ ‚ùå ‚ùå LXMERT ‚úÖ ‚úÖ ‚ùå M-CTC-T ‚úÖ ‚ùå ‚ùå M2M100 ‚úÖ ‚ùå ‚ùå MADLAD-400 ‚úÖ ‚úÖ ‚úÖ Mamba ‚úÖ ‚ùå ‚ùå mamba2 ‚úÖ ‚ùå ‚ùå Marian ‚úÖ ‚úÖ ‚úÖ MarkupLM ‚úÖ ‚ùå ‚ùå Mask2Former ‚úÖ ‚ùå ‚ùå MaskFormer ‚úÖ ‚ùå ‚ùå MatCha ‚úÖ ‚ùå ‚ùå mBART ‚úÖ ‚úÖ ‚úÖ mBART-50 ‚úÖ ‚úÖ ‚úÖ MEGA ‚úÖ ‚ùå ‚ùå Megatron-BERT ‚úÖ ‚ùå ‚ùå Megatron-GPT2 ‚úÖ ‚úÖ ‚úÖ MGP-STR ‚úÖ ‚ùå ‚ùå Mimi'),\n",
       " Document(metadata={'source': 'https://huggingface.co/docs/transformers/index', 'title': 'ü§ó Transformers', 'description': 'We‚Äôre on a journey to advance and democratize artificial intelligence through open source and open science.', 'language': 'No language found.'}, page_content='‚úÖ Mamba ‚úÖ ‚ùå ‚ùå mamba2 ‚úÖ ‚ùå ‚ùå Marian ‚úÖ ‚úÖ ‚úÖ MarkupLM ‚úÖ ‚ùå ‚ùå Mask2Former ‚úÖ ‚ùå ‚ùå MaskFormer ‚úÖ ‚ùå ‚ùå MatCha ‚úÖ ‚ùå ‚ùå mBART ‚úÖ ‚úÖ ‚úÖ mBART-50 ‚úÖ ‚úÖ ‚úÖ MEGA ‚úÖ ‚ùå ‚ùå Megatron-BERT ‚úÖ ‚ùå ‚ùå Megatron-GPT2 ‚úÖ ‚úÖ ‚úÖ MGP-STR ‚úÖ ‚ùå ‚ùå Mimi ‚úÖ ‚ùå ‚ùå Mistral ‚úÖ ‚úÖ ‚úÖ Mixtral ‚úÖ ‚ùå ‚ùå Mllama ‚úÖ ‚ùå ‚ùå mLUKE ‚úÖ ‚ùå ‚ùå MMS ‚úÖ ‚úÖ ‚úÖ MobileBERT ‚úÖ ‚úÖ ‚ùå MobileNetV1 ‚úÖ ‚ùå ‚ùå MobileNetV2 ‚úÖ ‚ùå ‚ùå MobileViT ‚úÖ ‚úÖ ‚ùå MobileViTV2 ‚úÖ ‚ùå ‚ùå ModernBERT ‚úÖ ‚ùå ‚ùå Moonshine ‚úÖ ‚ùå ‚ùå Moshi ‚úÖ ‚ùå ‚ùå MPNet ‚úÖ ‚úÖ ‚ùå MPT ‚úÖ ‚ùå ‚ùå MRA ‚úÖ ‚ùå ‚ùå MT5 ‚úÖ ‚úÖ ‚úÖ MusicGen ‚úÖ ‚ùå ‚ùå MusicGen Melody ‚úÖ ‚ùå ‚ùå MVP ‚úÖ ‚ùå ‚ùå NAT ‚úÖ ‚ùå ‚ùå Nemotron ‚úÖ ‚ùå ‚ùå Nezha ‚úÖ ‚ùå ‚ùå NLLB ‚úÖ ‚ùå ‚ùå NLLB-MOE ‚úÖ ‚ùå ‚ùå Nougat ‚úÖ ‚úÖ ‚úÖ Nystr√∂mformer ‚úÖ ‚ùå ‚ùå OLMo ‚úÖ ‚ùå ‚ùå OLMo2 ‚úÖ ‚ùå ‚ùå OLMoE ‚úÖ ‚ùå ‚ùå OmDet-Turbo ‚úÖ ‚ùå ‚ùå OneFormer ‚úÖ ‚ùå ‚ùå OpenAI GPT ‚úÖ ‚úÖ ‚ùå OpenAI GPT-2 ‚úÖ ‚úÖ ‚úÖ OpenLlama ‚úÖ ‚ùå ‚ùå OPT ‚úÖ ‚úÖ ‚úÖ OWL-ViT ‚úÖ ‚ùå ‚ùå OWLv2 ‚úÖ ‚ùå ‚ùå PaliGemma ‚úÖ ‚ùå ‚ùå PatchTSMixer ‚úÖ ‚ùå ‚ùå PatchTST ‚úÖ ‚ùå ‚ùå Pegasus ‚úÖ ‚úÖ ‚úÖ PEGASUS-X ‚úÖ ‚ùå ‚ùå Perceiver ‚úÖ ‚ùå ‚ùå Persimmon ‚úÖ ‚ùå ‚ùå Phi ‚úÖ ‚ùå ‚ùå Phi3 ‚úÖ ‚ùå ‚ùå Phimoe ‚úÖ ‚ùå ‚ùå PhoBERT ‚úÖ ‚úÖ ‚úÖ Pix2Struct ‚úÖ ‚ùå ‚ùå Pixtral ‚úÖ ‚ùå ‚ùå PLBart ‚úÖ ‚ùå ‚ùå PoolFormer ‚úÖ ‚ùå ‚ùå Pop2Piano ‚úÖ ‚ùå ‚ùå ProphetNet ‚úÖ ‚ùå ‚ùå'),\n",
       " Document(metadata={'source': 'https://huggingface.co/docs/transformers/index', 'title': 'ü§ó Transformers', 'description': 'We‚Äôre on a journey to advance and democratize artificial intelligence through open source and open science.', 'language': 'No language found.'}, page_content='‚úÖ ‚úÖ ‚úÖ PEGASUS-X ‚úÖ ‚ùå ‚ùå Perceiver ‚úÖ ‚ùå ‚ùå Persimmon ‚úÖ ‚ùå ‚ùå Phi ‚úÖ ‚ùå ‚ùå Phi3 ‚úÖ ‚ùå ‚ùå Phimoe ‚úÖ ‚ùå ‚ùå PhoBERT ‚úÖ ‚úÖ ‚úÖ Pix2Struct ‚úÖ ‚ùå ‚ùå Pixtral ‚úÖ ‚ùå ‚ùå PLBart ‚úÖ ‚ùå ‚ùå PoolFormer ‚úÖ ‚ùå ‚ùå Pop2Piano ‚úÖ ‚ùå ‚ùå ProphetNet ‚úÖ ‚ùå ‚ùå PVT ‚úÖ ‚ùå ‚ùå PVTv2 ‚úÖ ‚ùå ‚ùå QDQBert ‚úÖ ‚ùå ‚ùå Qwen2 ‚úÖ ‚ùå ‚ùå Qwen2Audio ‚úÖ ‚ùå ‚ùå Qwen2MoE ‚úÖ ‚ùå ‚ùå Qwen2VL ‚úÖ ‚ùå ‚ùå RAG ‚úÖ ‚úÖ ‚ùå REALM ‚úÖ ‚ùå ‚ùå RecurrentGemma ‚úÖ ‚ùå ‚ùå Reformer ‚úÖ ‚ùå ‚ùå RegNet ‚úÖ ‚úÖ ‚úÖ RemBERT ‚úÖ ‚úÖ ‚ùå ResNet ‚úÖ ‚úÖ ‚úÖ RetriBERT ‚úÖ ‚ùå ‚ùå RoBERTa ‚úÖ ‚úÖ ‚úÖ RoBERTa-PreLayerNorm ‚úÖ ‚úÖ ‚úÖ RoCBert ‚úÖ ‚ùå ‚ùå RoFormer ‚úÖ ‚úÖ ‚úÖ RT-DETR ‚úÖ ‚ùå ‚ùå RT-DETR-ResNet ‚úÖ ‚ùå ‚ùå RWKV ‚úÖ ‚ùå ‚ùå SAM ‚úÖ ‚úÖ ‚ùå SeamlessM4T ‚úÖ ‚ùå ‚ùå SeamlessM4Tv2 ‚úÖ ‚ùå ‚ùå SegFormer ‚úÖ ‚úÖ ‚ùå SegGPT ‚úÖ ‚ùå ‚ùå SEW ‚úÖ ‚ùå ‚ùå SEW-D ‚úÖ ‚ùå ‚ùå SigLIP ‚úÖ ‚ùå ‚ùå Speech Encoder decoder ‚úÖ ‚ùå ‚úÖ Speech2Text ‚úÖ ‚úÖ ‚ùå SpeechT5 ‚úÖ ‚ùå ‚ùå Splinter ‚úÖ ‚ùå ‚ùå SqueezeBERT ‚úÖ ‚ùå ‚ùå StableLm ‚úÖ ‚ùå ‚ùå Starcoder2 ‚úÖ ‚ùå ‚ùå SuperPoint ‚úÖ ‚ùå ‚ùå SwiftFormer ‚úÖ ‚úÖ ‚ùå Swin Transformer ‚úÖ ‚úÖ ‚ùå Swin Transformer V2 ‚úÖ ‚ùå ‚ùå Swin2SR ‚úÖ ‚ùå ‚ùå SwitchTransformers ‚úÖ ‚ùå ‚ùå T5 ‚úÖ ‚úÖ ‚úÖ T5v1.1 ‚úÖ ‚úÖ ‚úÖ Table Transformer ‚úÖ ‚ùå ‚ùå TAPAS ‚úÖ ‚úÖ ‚ùå TAPEX ‚úÖ ‚úÖ ‚úÖ TextNet ‚úÖ ‚ùå ‚ùå Time Series Transformer ‚úÖ ‚ùå ‚ùå'),\n",
       " Document(metadata={'source': 'https://huggingface.co/docs/transformers/index', 'title': 'ü§ó Transformers', 'description': 'We‚Äôre on a journey to advance and democratize artificial intelligence through open source and open science.', 'language': 'No language found.'}, page_content='Transformer ‚úÖ ‚úÖ ‚ùå Swin Transformer V2 ‚úÖ ‚ùå ‚ùå Swin2SR ‚úÖ ‚ùå ‚ùå SwitchTransformers ‚úÖ ‚ùå ‚ùå T5 ‚úÖ ‚úÖ ‚úÖ T5v1.1 ‚úÖ ‚úÖ ‚úÖ Table Transformer ‚úÖ ‚ùå ‚ùå TAPAS ‚úÖ ‚úÖ ‚ùå TAPEX ‚úÖ ‚úÖ ‚úÖ TextNet ‚úÖ ‚ùå ‚ùå Time Series Transformer ‚úÖ ‚ùå ‚ùå TimeSformer ‚úÖ ‚ùå ‚ùå TimmWrapperModel ‚úÖ ‚ùå ‚ùå Trajectory Transformer ‚úÖ ‚ùå ‚ùå Transformer-XL ‚úÖ ‚úÖ ‚ùå TrOCR ‚úÖ ‚ùå ‚ùå TVLT ‚úÖ ‚ùå ‚ùå TVP ‚úÖ ‚ùå ‚ùå UDOP ‚úÖ ‚ùå ‚ùå UL2 ‚úÖ ‚úÖ ‚úÖ UMT5 ‚úÖ ‚ùå ‚ùå UniSpeech ‚úÖ ‚ùå ‚ùå UniSpeechSat ‚úÖ ‚ùå ‚ùå UnivNet ‚úÖ ‚ùå ‚ùå UPerNet ‚úÖ ‚ùå ‚ùå VAN ‚úÖ ‚ùå ‚ùå VideoLlava ‚úÖ ‚ùå ‚ùå VideoMAE ‚úÖ ‚ùå ‚ùå ViLT ‚úÖ ‚ùå ‚ùå VipLlava ‚úÖ ‚ùå ‚ùå Vision Encoder decoder ‚úÖ ‚úÖ ‚úÖ VisionTextDualEncoder ‚úÖ ‚úÖ ‚úÖ VisualBERT ‚úÖ ‚ùå ‚ùå ViT ‚úÖ ‚úÖ ‚úÖ ViT Hybrid ‚úÖ ‚ùå ‚ùå VitDet ‚úÖ ‚ùå ‚ùå ViTMAE ‚úÖ ‚úÖ ‚ùå ViTMatte ‚úÖ ‚ùå ‚ùå ViTMSN ‚úÖ ‚ùå ‚ùå VitPose ‚úÖ ‚ùå ‚ùå VitPoseBackbone ‚úÖ ‚ùå ‚ùå VITS ‚úÖ ‚ùå ‚ùå ViViT ‚úÖ ‚ùå ‚ùå Wav2Vec2 ‚úÖ ‚úÖ ‚úÖ Wav2Vec2-BERT ‚úÖ ‚ùå ‚ùå Wav2Vec2-Conformer ‚úÖ ‚ùå ‚ùå Wav2Vec2Phoneme ‚úÖ ‚úÖ ‚úÖ WavLM ‚úÖ ‚ùå ‚ùå Whisper ‚úÖ ‚úÖ ‚úÖ X-CLIP ‚úÖ ‚ùå ‚ùå X-MOD ‚úÖ ‚ùå ‚ùå XGLM ‚úÖ ‚úÖ ‚úÖ XLM ‚úÖ ‚úÖ ‚ùå XLM-ProphetNet ‚úÖ ‚ùå ‚ùå XLM-RoBERTa ‚úÖ ‚úÖ ‚úÖ XLM-RoBERTa-XL ‚úÖ ‚ùå ‚ùå XLM-V ‚úÖ ‚úÖ ‚úÖ XLNet ‚úÖ ‚úÖ ‚ùå XLS-R ‚úÖ ‚úÖ ‚úÖ XLSR-Wav2Vec2 ‚úÖ ‚úÖ ‚úÖ YOLOS ‚úÖ ‚ùå ‚ùå YOSO ‚úÖ ‚ùå ‚ùå Zamba ‚úÖ'),\n",
       " Document(metadata={'source': 'https://huggingface.co/docs/transformers/index', 'title': 'ü§ó Transformers', 'description': 'We‚Äôre on a journey to advance and democratize artificial intelligence through open source and open science.', 'language': 'No language found.'}, page_content='‚úÖ ‚úÖ ‚úÖ X-CLIP ‚úÖ ‚ùå ‚ùå X-MOD ‚úÖ ‚ùå ‚ùå XGLM ‚úÖ ‚úÖ ‚úÖ XLM ‚úÖ ‚úÖ ‚ùå XLM-ProphetNet ‚úÖ ‚ùå ‚ùå XLM-RoBERTa ‚úÖ ‚úÖ ‚úÖ XLM-RoBERTa-XL ‚úÖ ‚ùå ‚ùå XLM-V ‚úÖ ‚úÖ ‚úÖ XLNet ‚úÖ ‚úÖ ‚ùå XLS-R ‚úÖ ‚úÖ ‚úÖ XLSR-Wav2Vec2 ‚úÖ ‚úÖ ‚úÖ YOLOS ‚úÖ ‚ùå ‚ùå YOSO ‚úÖ ‚ùå ‚ùå Zamba ‚úÖ ‚ùå ‚ùå ZoeDepth ‚úÖ ‚ùå ‚ùå < > Update on GitHub'),\n",
       " Document(metadata={'source': 'https://huggingface.co/docs/transformers/index', 'title': 'ü§ó Transformers', 'description': 'We‚Äôre on a journey to advance and democratize artificial intelligence through open source and open science.', 'language': 'No language found.'}, page_content='Quick tour‚Üí\\n\\n\\nü§ó Transformers\\nIf you are looking for custom support from the Hugging Face team\\nContents\\nSupported models and frameworks')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=200)\n",
    "splitted_docs = splitter.split_documents(docs)\n",
    "splitted_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "embedding = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.faiss.FAISS at 0x19537eb7be0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "db = FAISS.from_documents(splitted_docs,embedding)\n",
    "db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query From vectorDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ü§ó Transformers State-of-the-art Machine Learning for PyTorch, TensorFlow, and JAX. ü§ó Transformers provides APIs and tools to easily download and train state-of-the-art pretrained models. Using pretrained models can reduce your compute costs, carbon footprint, and save you the time and resources required to train a model from scratch. These models support common tasks in different modalities, such as: üìù Natural Language Processing: text classification, named entity recognition, question answering, language modeling, code generation, summarization, translation, multiple choice, and text generation.\\nüñºÔ∏è Computer Vision: image classification, object detection, and segmentation.\\nüó£Ô∏è Audio: automatic speech recognition and audio classification.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Which common tasks are supportted by Transformer models in different modalities?\"\n",
    "result = db.similarity_search(query)\n",
    "result[0].page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load LLM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.Completions object at 0x00000195A49221A0> async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x00000195A4887940> root_client=<openai.OpenAI object at 0x00000195A4922AA0> root_async_client=<openai.AsyncOpenAI object at 0x00000195A49208B0> model_name='gpt-4o' model_kwargs={} openai_api_key=SecretStr('**********')\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieval Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  context: RunnableLambda(format_docs)\n",
       "}), kwargs={}, config={'run_name': 'format_inputs'}, config_factories=[])\n",
       "| ChatPromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template='\\nAnswer the following question based only on the provided context:\\n<context>\\n{context}\\n'), additional_kwargs={})])\n",
       "| ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x00000195A49221A0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x00000195A4887940>, root_client=<openai.OpenAI object at 0x00000195A4922AA0>, root_async_client=<openai.AsyncOpenAI object at 0x00000195A49208B0>, model_name='gpt-4o', model_kwargs={}, openai_api_key=SecretStr('**********'))\n",
       "| StrOutputParser(), kwargs={}, config={'run_name': 'stuff_documents_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "\"\"\"\n",
    "Answer the following question based only on the provided context:\n",
    "<context>\n",
    "{context}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "document_chain = create_stuff_documents_chain(llm,prompt)\n",
    "document_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Transformer models are versatile and support a range of tasks across different modalities. In text or language processing, they support tasks such as translation, text generation, sentiment analysis, and summarization. For vision tasks, they are used in object detection, image classification, and image segmentation. In speech processing, they facilitate tasks like speech recognition and text-to-speech conversion. These models excel in handling and generating data across these modalities due to their ability to capture long-range dependencies and contextual information.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "document_chain.invoke({\n",
    "    \"input\":\"Which common tasks are supportted by Transformer models in different modalities?\",\n",
    "    \"context\": [Document(page_content=\"Which common tasks are supportted by Transformer models in different modalities?\")]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### So far the input we are passing directly to LLM model but at first we want it to go through our vectordb. By this way we will first search related information from vector db and that information along with input will be passed to LLM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  context: RunnableBinding(bound=RunnableLambda(lambda x: x['input'])\n",
       "           | VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000019537EB7BE0>, search_kwargs={}), kwargs={}, config={'run_name': 'retrieve_documents'}, config_factories=[])\n",
       "})\n",
       "| RunnableAssign(mapper={\n",
       "    answer: RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "              context: RunnableLambda(format_docs)\n",
       "            }), kwargs={}, config={'run_name': 'format_inputs'}, config_factories=[])\n",
       "            | ChatPromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template='\\nAnswer the following question based only on the provided context:\\n<context>\\n{context}\\n'), additional_kwargs={})])\n",
       "            | ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x00000195A49221A0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x00000195A4887940>, root_client=<openai.OpenAI object at 0x00000195A4922AA0>, root_async_client=<openai.AsyncOpenAI object at 0x00000195A49208B0>, model_name='gpt-4o', model_kwargs={}, openai_api_key=SecretStr('**********'))\n",
       "            | StrOutputParser(), kwargs={}, config={'run_name': 'stuff_documents_chain'}, config_factories=[])\n",
       "  }), kwargs={}, config={'run_name': 'retrieval_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Retriver :  input =>   retriever => vectordb\n",
    "from langchain.chains import create_retrieval_chain\n",
    "retriever = db.as_retriever()\n",
    "retrieval_chain = create_retrieval_chain(retriever,document_chain)\n",
    "retrieval_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'Does transformer supports PyTorch, TensorFlow, and JAX',\n",
       " 'context': [Document(id='1889cc00-4565-4e84-8665-f61550c3b3a5', metadata={'source': 'https://huggingface.co/docs/transformers/index', 'title': 'ü§ó Transformers', 'description': 'We‚Äôre on a journey to advance and democratize artificial intelligence through open source and open science.', 'language': 'No language found.'}, page_content='ü§ó Transformers State-of-the-art Machine Learning for PyTorch, TensorFlow, and JAX. ü§ó Transformers provides APIs and tools to easily download and train state-of-the-art pretrained models. Using pretrained models can reduce your compute costs, carbon footprint, and save you the time and resources required to train a model from scratch. These models support common tasks in different modalities, such as: üìù Natural Language Processing: text classification, named entity recognition, question answering, language modeling, code generation, summarization, translation, multiple choice, and text generation.\\nüñºÔ∏è Computer Vision: image classification, object detection, and segmentation.\\nüó£Ô∏è Audio: automatic speech recognition and audio classification.'),\n",
       "  Document(id='feda9fc2-7906-4e09-b0cb-0e0475bfa1de', metadata={'source': 'https://huggingface.co/docs/transformers/index', 'title': 'ü§ó Transformers', 'description': 'We‚Äôre on a journey to advance and democratize artificial intelligence through open source and open science.', 'language': 'No language found.'}, page_content='Flax), PyTorch, and/or TensorFlow. Model PyTorch support TensorFlow support Flax Support ALBERT ‚úÖ ‚úÖ ‚úÖ ALIGN ‚úÖ ‚ùå ‚ùå AltCLIP ‚úÖ ‚ùå ‚ùå Aria ‚úÖ ‚ùå ‚ùå AriaText ‚úÖ ‚ùå ‚ùå Audio Spectrogram Transformer ‚úÖ ‚ùå ‚ùå Autoformer ‚úÖ ‚ùå ‚ùå Bamba ‚úÖ ‚ùå ‚ùå Bark ‚úÖ ‚ùå ‚ùå BART ‚úÖ ‚úÖ ‚úÖ BARThez ‚úÖ ‚úÖ ‚úÖ BARTpho ‚úÖ ‚úÖ ‚úÖ BEiT ‚úÖ ‚ùå ‚úÖ BERT ‚úÖ ‚úÖ ‚úÖ Bert Generation ‚úÖ ‚ùå ‚ùå BertJapanese ‚úÖ ‚úÖ ‚úÖ BERTweet ‚úÖ ‚úÖ ‚úÖ BigBird ‚úÖ ‚ùå ‚úÖ BigBird-Pegasus ‚úÖ ‚ùå ‚ùå BioGpt ‚úÖ ‚ùå ‚ùå BiT ‚úÖ ‚ùå ‚ùå Blenderbot ‚úÖ ‚úÖ ‚úÖ BlenderbotSmall ‚úÖ ‚úÖ ‚úÖ BLIP ‚úÖ ‚úÖ ‚ùå BLIP-2 ‚úÖ ‚ùå ‚ùå BLOOM ‚úÖ ‚ùå ‚úÖ BORT ‚úÖ ‚úÖ ‚úÖ BridgeTower ‚úÖ ‚ùå ‚ùå BROS ‚úÖ ‚ùå ‚ùå ByT5 ‚úÖ ‚úÖ ‚úÖ CamemBERT ‚úÖ ‚úÖ ‚ùå CANINE ‚úÖ ‚ùå ‚ùå Chameleon ‚úÖ ‚ùå ‚ùå Chinese-CLIP ‚úÖ ‚ùå ‚ùå CLAP ‚úÖ ‚ùå ‚ùå CLIP ‚úÖ ‚úÖ ‚úÖ CLIPSeg ‚úÖ ‚ùå ‚ùå CLVP ‚úÖ ‚ùå ‚ùå CodeGen ‚úÖ ‚ùå ‚ùå CodeLlama ‚úÖ ‚ùå ‚úÖ Cohere ‚úÖ ‚ùå ‚ùå Cohere2 ‚úÖ ‚ùå ‚ùå ColPali ‚úÖ ‚ùå ‚ùå Conditional DETR ‚úÖ ‚ùå ‚ùå ConvBERT ‚úÖ ‚úÖ ‚ùå ConvNeXT ‚úÖ ‚úÖ ‚ùå ConvNeXTV2 ‚úÖ ‚úÖ ‚ùå CPM ‚úÖ ‚úÖ ‚úÖ CPM-Ant ‚úÖ ‚ùå ‚ùå CTRL ‚úÖ ‚úÖ ‚ùå CvT ‚úÖ ‚úÖ ‚ùå DAC ‚úÖ ‚ùå ‚ùå Data2VecAudio ‚úÖ ‚ùå ‚ùå Data2VecText ‚úÖ ‚ùå ‚ùå Data2VecVision ‚úÖ ‚úÖ ‚ùå DBRX ‚úÖ ‚ùå ‚ùå DeBERTa ‚úÖ ‚úÖ ‚ùå DeBERTa-v2 ‚úÖ ‚úÖ ‚ùå Decision Transformer ‚úÖ ‚ùå ‚ùå Deformable DETR ‚úÖ ‚ùå ‚ùå DeiT ‚úÖ ‚úÖ'),\n",
       "  Document(id='94b08dbc-dddf-4efe-b6d6-fb54add8535b', metadata={'source': 'https://huggingface.co/docs/transformers/index', 'title': 'ü§ó Transformers', 'description': 'We‚Äôre on a journey to advance and democratize artificial intelligence through open source and open science.', 'language': 'No language found.'}, page_content='üêô Multimodal: table question answering, optical character recognition, information extraction from scanned documents, video classification, and visual question answering. ü§ó Transformers support framework interoperability between PyTorch, TensorFlow, and JAX. This provides the flexibility to use a different framework at each stage of a model‚Äôs life; train a model in three lines of code in one framework, and load it for inference in another. Models can also be exported to a format like ONNX and TorchScript for deployment in production environments. Join the growing community on the Hub, forum, or Discord today!  If you are looking for custom support from the Hugging Face team   Contents The documentation is organized into five sections: GET STARTED provides a quick tour of the library and installation instructions to get up and running. TUTORIALS are a great place to start if you‚Äôre a beginner. This section will help you gain the basic skills you need to start using the library. HOW-TO'),\n",
       "  Document(id='7c0cd7c7-61ad-4f0c-96ca-ca00efb44e90', metadata={'source': 'https://huggingface.co/docs/transformers/index', 'title': 'ü§ó Transformers', 'description': 'We‚Äôre on a journey to advance and democratize artificial intelligence through open source and open science.', 'language': 'No language found.'}, page_content='Quick tour‚Üí\\n\\n\\nü§ó Transformers\\nIf you are looking for custom support from the Hugging Face team\\nContents\\nSupported models and frameworks')],\n",
       " 'answer': 'Which models support all three frameworks: PyTorch, TensorFlow, and Flax?\\n\\n- ALBERT\\n- BART\\n- BARThez\\n- BARTpho\\n- BERT\\n- BertJapanese\\n- BERTweet\\n- Blenderbot\\n- BlenderbotSmall\\n- CamemBERT\\n- CPM'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Get the response from LLM\n",
    "response = retrieval_chain.invoke({\"input\":\"Does transformer supports PyTorch, TensorFlow, and JAX\"})\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Which models support all three frameworks: PyTorch, TensorFlow, and Flax?\\n\\n- ALBERT\\n- BART\\n- BARThez\\n- BARTpho\\n- BERT\\n- BertJapanese\\n- BERTweet\\n- Blenderbot\\n- BlenderbotSmall\\n- CamemBERT\\n- CPM'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='1889cc00-4565-4e84-8665-f61550c3b3a5', metadata={'source': 'https://huggingface.co/docs/transformers/index', 'title': 'ü§ó Transformers', 'description': 'We‚Äôre on a journey to advance and democratize artificial intelligence through open source and open science.', 'language': 'No language found.'}, page_content='ü§ó Transformers State-of-the-art Machine Learning for PyTorch, TensorFlow, and JAX. ü§ó Transformers provides APIs and tools to easily download and train state-of-the-art pretrained models. Using pretrained models can reduce your compute costs, carbon footprint, and save you the time and resources required to train a model from scratch. These models support common tasks in different modalities, such as: üìù Natural Language Processing: text classification, named entity recognition, question answering, language modeling, code generation, summarization, translation, multiple choice, and text generation.\\nüñºÔ∏è Computer Vision: image classification, object detection, and segmentation.\\nüó£Ô∏è Audio: automatic speech recognition and audio classification.'),\n",
       " Document(id='feda9fc2-7906-4e09-b0cb-0e0475bfa1de', metadata={'source': 'https://huggingface.co/docs/transformers/index', 'title': 'ü§ó Transformers', 'description': 'We‚Äôre on a journey to advance and democratize artificial intelligence through open source and open science.', 'language': 'No language found.'}, page_content='Flax), PyTorch, and/or TensorFlow. Model PyTorch support TensorFlow support Flax Support ALBERT ‚úÖ ‚úÖ ‚úÖ ALIGN ‚úÖ ‚ùå ‚ùå AltCLIP ‚úÖ ‚ùå ‚ùå Aria ‚úÖ ‚ùå ‚ùå AriaText ‚úÖ ‚ùå ‚ùå Audio Spectrogram Transformer ‚úÖ ‚ùå ‚ùå Autoformer ‚úÖ ‚ùå ‚ùå Bamba ‚úÖ ‚ùå ‚ùå Bark ‚úÖ ‚ùå ‚ùå BART ‚úÖ ‚úÖ ‚úÖ BARThez ‚úÖ ‚úÖ ‚úÖ BARTpho ‚úÖ ‚úÖ ‚úÖ BEiT ‚úÖ ‚ùå ‚úÖ BERT ‚úÖ ‚úÖ ‚úÖ Bert Generation ‚úÖ ‚ùå ‚ùå BertJapanese ‚úÖ ‚úÖ ‚úÖ BERTweet ‚úÖ ‚úÖ ‚úÖ BigBird ‚úÖ ‚ùå ‚úÖ BigBird-Pegasus ‚úÖ ‚ùå ‚ùå BioGpt ‚úÖ ‚ùå ‚ùå BiT ‚úÖ ‚ùå ‚ùå Blenderbot ‚úÖ ‚úÖ ‚úÖ BlenderbotSmall ‚úÖ ‚úÖ ‚úÖ BLIP ‚úÖ ‚úÖ ‚ùå BLIP-2 ‚úÖ ‚ùå ‚ùå BLOOM ‚úÖ ‚ùå ‚úÖ BORT ‚úÖ ‚úÖ ‚úÖ BridgeTower ‚úÖ ‚ùå ‚ùå BROS ‚úÖ ‚ùå ‚ùå ByT5 ‚úÖ ‚úÖ ‚úÖ CamemBERT ‚úÖ ‚úÖ ‚ùå CANINE ‚úÖ ‚ùå ‚ùå Chameleon ‚úÖ ‚ùå ‚ùå Chinese-CLIP ‚úÖ ‚ùå ‚ùå CLAP ‚úÖ ‚ùå ‚ùå CLIP ‚úÖ ‚úÖ ‚úÖ CLIPSeg ‚úÖ ‚ùå ‚ùå CLVP ‚úÖ ‚ùå ‚ùå CodeGen ‚úÖ ‚ùå ‚ùå CodeLlama ‚úÖ ‚ùå ‚úÖ Cohere ‚úÖ ‚ùå ‚ùå Cohere2 ‚úÖ ‚ùå ‚ùå ColPali ‚úÖ ‚ùå ‚ùå Conditional DETR ‚úÖ ‚ùå ‚ùå ConvBERT ‚úÖ ‚úÖ ‚ùå ConvNeXT ‚úÖ ‚úÖ ‚ùå ConvNeXTV2 ‚úÖ ‚úÖ ‚ùå CPM ‚úÖ ‚úÖ ‚úÖ CPM-Ant ‚úÖ ‚ùå ‚ùå CTRL ‚úÖ ‚úÖ ‚ùå CvT ‚úÖ ‚úÖ ‚ùå DAC ‚úÖ ‚ùå ‚ùå Data2VecAudio ‚úÖ ‚ùå ‚ùå Data2VecText ‚úÖ ‚ùå ‚ùå Data2VecVision ‚úÖ ‚úÖ ‚ùå DBRX ‚úÖ ‚ùå ‚ùå DeBERTa ‚úÖ ‚úÖ ‚ùå DeBERTa-v2 ‚úÖ ‚úÖ ‚ùå Decision Transformer ‚úÖ ‚ùå ‚ùå Deformable DETR ‚úÖ ‚ùå ‚ùå DeiT ‚úÖ ‚úÖ'),\n",
       " Document(id='94b08dbc-dddf-4efe-b6d6-fb54add8535b', metadata={'source': 'https://huggingface.co/docs/transformers/index', 'title': 'ü§ó Transformers', 'description': 'We‚Äôre on a journey to advance and democratize artificial intelligence through open source and open science.', 'language': 'No language found.'}, page_content='üêô Multimodal: table question answering, optical character recognition, information extraction from scanned documents, video classification, and visual question answering. ü§ó Transformers support framework interoperability between PyTorch, TensorFlow, and JAX. This provides the flexibility to use a different framework at each stage of a model‚Äôs life; train a model in three lines of code in one framework, and load it for inference in another. Models can also be exported to a format like ONNX and TorchScript for deployment in production environments. Join the growing community on the Hub, forum, or Discord today!  If you are looking for custom support from the Hugging Face team   Contents The documentation is organized into five sections: GET STARTED provides a quick tour of the library and installation instructions to get up and running. TUTORIALS are a great place to start if you‚Äôre a beginner. This section will help you gain the basic skills you need to start using the library. HOW-TO'),\n",
       " Document(id='7c0cd7c7-61ad-4f0c-96ca-ca00efb44e90', metadata={'source': 'https://huggingface.co/docs/transformers/index', 'title': 'ü§ó Transformers', 'description': 'We‚Äôre on a journey to advance and democratize artificial intelligence through open source and open science.', 'language': 'No language found.'}, page_content='Quick tour‚Üí\\n\\n\\nü§ó Transformers\\nIf you are looking for custom support from the Hugging Face team\\nContents\\nSupported models and frameworks')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response[\"context\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv_lang",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
